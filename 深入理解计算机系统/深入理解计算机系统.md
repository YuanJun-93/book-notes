### 第一章 计算机系统漫游

#### 1.1 信息就是位+上下文

hello.c程序是以字节序列的方式存在文件中的

系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。

区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文

- 在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令

#### 1.2 程序被其他程序翻译成不同的格式

在Unix系统上，从源文件到目标文件的转化是由编译器驱动程序完成的

- ``gcc -o hello hello.c``
- GCC编译器驱动程序读取源程序文件hello.c，并翻译成一个可执行目标文件hello

翻译过程分成四个阶段

- 预处理阶段。根据以字符#开头的命令，修改原始的C程序
- 编译阶段。编译器（cc1）将文本文件hello.i翻译成文本文件hello.s。它包含一个汇编语言程序
- 汇编阶段。 汇编器将hello.s翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序的格式，并将结果保存在目标文件hello.o中（二进制文件）
- 链接阶段。如果调用了其他函数，需要将这个函数的文件合并到hello.o程序中

#### 1.4 处理器读并解释储存在内存中的指令

#####  1.4.1 系统的硬件组成

- 总线。它携带信息字节并负责在各个部件间传递，通常总线被设计成传送定长的字节块，也就是字（word）
- I/O设备。I/O（输入/输出）设备是系统与外部世界的联系通道，每个I/O设备都通过一个控制器或适配器与I/O总线相连
  - 控制器是I/O设备本身或者系统的主印制电路板（主板）上的芯片组
  - 适配器是一块插在主板插槽上的卡
  - 它们功能都是在I/O总线和I/O设备之间传递信息
- 主存。临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据
  - 从物理上来说，主存是由一组动态随机存取存储器（DRAM）芯片组成
  - 从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），从0开始
- 处理器。解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC），在任何时刻，PC都指向主存中的某条机器语言指令（即含有该条指令的地址）
  - 加载：从主存复制一个字节或者一个字到寄存器，覆盖寄存器原来内容
  - 存储：从寄存器复制一个字节或者一个字到主存的某个位置，覆盖这个位置原来的内容
  - 操作：把两个寄存器内容复制到ALU，ALU对这两个字做算术运算，并将结果放到一个寄存器中，覆盖该寄存器原来的内容
  - 跳转：从指令本身中抽取一个字，并将这个字复制到程序计数器（PC）中，覆盖原本PC中的值

#### 1.5 高速缓存至关重要

L1和L2高速缓存是用一种静态随机访问存储器（SRAM）

在高速缓存里面放经常访问的数据

#### 1.7 操作系统管理硬件

操作系统是应用程序和硬件之间插入的一层软件，**所有应用程序对硬件的操作尝试都必须通过操作系统**

操作系统两个基本功能

- 防止硬件被失控的应用程序滥用
- 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备

文件是对I/O设备抽象的表示

虚拟内存是对主存和硬盘I/O设备的抽象表示

进程是对处理器、主存和I/O设备的抽象表示

##### 1.7.1 进程

进程是操作系统对一个正在运行的程序的一种抽象。

并发运行，是说一个进程的指令和另一个进程的指令是交错执行的（上下文切换）。

操作系统保持跟踪进程运行所需的所有状态信息，也就是上下文

- 比如PC和寄存器文件的当前值，以及主存的内容

从一个进程到了一个进程到转换是由操作系统内核管理的，内核是操作系统代码常驻主存的部分，当应用程序需要操作系统的某些操作时，比如读写文件，**它就执行一条特殊的系统调用（system call）指令，将控制权传递给内核**。然后内核执行被请求的操作并返回应用程序

**内核不是一个独立的进程，它是系统管理全部进程所用代码和数据结构的集合**

##### 1.7.2 线程

一个进程可以由多个称为线程的执行单元组成，**每个线程都运行在进程上下文中，并共享同样的代码和数据**

多线程之间比多进程之间更容易共享数据

线程一般比进程更高效

##### 1.7.3 虚拟内存

虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。

**每个进程看到的内存都是一致的，称为虚拟地址空间**

进程的虚拟地址空间，从最低的地址开始，逐步向上

- 程序代码和数据。直接按照可执行目标文件的内容初始化的，在进程一开始运行时就指定了大小
- 堆。当调用malloc和free这样的C标准库函数时，堆可以动态地扩展和收缩
- 共享库。大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区域
- 栈。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用，每次调用一个函数时，栈就会增长，从一个函数返回时，栈就会收缩
- 内核虚拟空间。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。

基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为磁盘的高速缓存

##### 1.7.4 文件

文件就是字节序列，仅此而已。

每个I/O设备，包括磁盘、键盘、显示器，甚至网络都可以看成是文件。

系统中的所有输入输出都是通过使用一小组称为UnixI/O的系统函数调用读写文件来实现的。

#### 1.9 重要主题

##### 1.9.2 并发和并行

**1.线程级并发**

单处理器中，传统意义上，并发只是模拟出来的，使一台计算机在它正在执行的进程间快速切换来实现的。

多核处理器是将多个CPU（称为“核”）集成到一个集成电路芯片上。

典型多核处理器的组织结构，其中微处理器芯片有4个CPU核，每个核都有自己的L1核L2高速缓存，其中的L1高速缓存分为两个部分——一个保存最近取到的指令，了一个存放数据。**这些核共享更高层次的高速缓存，以及到主存的接口**

超线程，有时称为同时多线程，是一项运行一个CPU执行多个控制流的技术。

- 它涉及CPU某些硬件有多个备份，比如程序计数器和寄存器文件，而其他的硬件部分只有一份，比如执行浮点算术运算的单元
- 常规的处理器需要大约20000个时钟周期做不同线程间转换，而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程，**使得CPU能够更好地利用它的处理资源**

多处理器的使用可以从两方面提高系统性能

- 减少了在执行多个任务时模拟并发的需要
- 可以使应用程序运行得更快

**2.指令级并行**

现代处理器可以同时执行多条指令的属性称为指令级并行

如果处理器可以达到比一个周期一条指令更快的执行速率，就称为超标量处理器，大多数现代处理器都支持超标量操作

**3.单指令、多数据并行**

许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即SIMD并行

### 第二章 信息的表示和处理

无符号编码基于传统的二进制表示法，表示大于或者等于零的数字。

补码编码是表示有符号整数的最常见的方式，有符号整数就是可以为正或者为负的数字

浮点数编码是表示实数的科学记数法的以2为基数的版本

**大量的计算机的安全漏洞都是由于计算机算术运算的微妙细节引发的**

#### 2.1 信息存储

大多数计算机使用8位的块，或者字节（byte），作为最小的可寻址的内存单位，而不是访问内存中单独的位

内存的每个字节都由唯一的数字来标识，称为地址，所有地址的集合称为虚拟地址空间

每个程序对象可以简单地视为一个字节块，而程序本身就是一个字节序列

##### 2.1.2 字数据大小

每台计算机都有一个字长（word size），**字长决定虚拟地址空间的大小**

- 假设字长为w位，虚拟地址的范围0～（2的w次方）-1

**32位字长，限制虚拟地址空间为4GB，64位是16EB**

一般数据格式都是4字节，double和int64是8字节，short2字节，char1字节

小端表示法：最低有效字节在最前面，[67，45，23，01]

大端表示法：最高有效字节在最前面，[01，23，45，67]

**Android和IOS只能使用小端模式**

Unicode（统一字符集），使用32位来表示字符

异或交换值

```c
y = x ^ y;
x = x ^ y;
y = x ^ y;
```

#### 2.2 整数表示

##### 2.2.1 整型数据类型

负数的范围逼整数的范围大1

C和C++都支持有符号和无符号数，Java只支持有符号数

43～108 jump

补码等等一大堆运算跳过了，以后回来看

### 第三章 程序的机器级表示

#### 3.2 程序编码

##### 3.2.1 机器级代码

程序内存包含

- 程序的可执行机器代码
- 操作系统需要的一些信息
- 用来管理过程调用和返回的运行时栈
- 用户分配的内存块

GCC运行编译器，-s产生一个.s的汇编文件，里面都是汇编代码，-c产生.o结尾的目标文件

#### 3.3 数据格式

Intel用术语：字（word）表示16位数据类型，32位称为双字，64位称为四字

浮点数主要有两种形式：单精度（4字节）值，双精度（8字节）值

#### 3.4 访问信息

一个x86-64的中央处理单元（CPU）包含一组16个存储64位值的通用目的寄存器：从%r8到%r15

##### 3.4.2 数据传送指令

MOV

- movb，1
- movw，2
- movl，4
- movq，8字节

Mov指令操作：第一个是原操作数，第二个是目的操作数

##### 3.6.6 用条件传送来实现条件分支

**if else效率低**

```c
long absdiff(long x, long y){
  long result;
  if(x < y)
    result = y - x;
  else
    result = x - y;
  return result;
}
```

模拟汇编代码，基于条件数据传送的代码，使用条件赋值的实现

```C
long cmovdiff(long x, long y){
	long rval = y-x;
  long eval = x-y;
  long ntest = x >= y;
  if(ntest)
    rval = eval
  return rval;
}
```

**基于条件数据传送的代码会比基于条件控制转移的代码性能要好**

##### 3.6.8 switch语句

switch语句可以根据一个整数索引值进行多重分支

- 可以通过使用跳转表（jump table）这种数据结构使得实现更加高效
- 跳转表是一个数组，优点是执行开关语句的时间与开关情况的数量无关
- 当开关情况数量比较多（4个以上），并且值的范围跨度比较小时，就会使用跳转表

#### 3.7 过程

过程的形式多样：函数、方法、子例程、处理函数等等

假设过程调用P调用过程Q，Q执行后返回到P

- 传递控制。在进入过程Q的时候，程序计数器必须被设置为Q的代码的起始地址，然后在返回时，要把程序计数器设置为P中调用Q后面那条指令的地址
- 传递数据。P必须能够向Q提供一个或多个参数，Q必须能够向P返回一个值
- 分配和释放内存。在开始时，Q可能需要为局部变量分配空间，而在返回前，又必须释放这些存储空间

##### 3.7.1 运行时栈

程序用栈来管理它的过程所需要的存储空间，栈和程序寄存器存放着传递控制和数据、分配内存所需要的信息。

- 当P调用Q时，控制和数据信息添加到栈尾
- 当P返回时，这些信息就会被释放掉

当x86-64过程需要的存储空间超出寄存器能够存放的大小时，就会在栈上分配空间

- **这个部分称为过程的栈帧**

##### 3.7.2 转移控制

将控制从函数P转移到函数Q需要简单地把程序计数器（PC）设置为Q的代码的起始位置

- 当从Q返回时，处理器必须记录好它需要继续P当执行的代码位置

##### 3.7.4 栈上的局部存储

有些时候，局部数据必须存放在内存中，常见的情况

- 寄存器不足够存放所有的本地数据
- 对一个局部变量使用地址运算符“&”，因此必须能够为它产生一个地址
- 某些局部变量是数组或结构，因此必须能够通过数组或结构引用被访问到

函数P调用两层Q

```c
long P(long x, long y){
  long u = Q(y);
  long v = Q(x);
  return u + v;
}
```

汇编代码

```c
P:
	pushq %rbp
  pushq %rbx
  subq $8, %rsp
  movq %rdi, %rbp
  movq %rsi, %rdi
  call Q
  movq %rax, %rbx
  movq %rbp, %rdi
  call Q
  addq %rbx, %rax
  addq %8, %rsp
  popq %rbx
  popq %rbp
  ret
```

在第一次调用中，必须保存x的值，第二次调用中，必须保存Q(y)的值

#### 3.8 数组分配和访问

##### 3.8.2 指针运算

单操作数操作符'&'和'*'可以产生指针和间接引用指针

对于一个对象的表达式Expr

- *AExpr表示的是值
- &Expr表示的是指向这个地址的指针
- 表达式Expr与*&Expr是等价的
- 引用数组A[i]等同于表达式*(A+ i )

##### 3.8.4 定长数组

好的编码习惯

```c
#define N 16
typedef int fix_matrix[N][N]
```

#### 3.9 异质的数据结构

##### 3.9.3 数据对齐

许多计算机系统对基本数据类型的合法地址做出来一些限制，要求某种类型对象的地址必须是某个值K（通常是2、4或8）的倍数

- 这种对齐限制简化了形成处理器和内存系统之间接口的硬件设计

假设一个处理器总是从内存取8个字节，则地址必须为8的倍数。

- **如果我们能保证将所有的double类型数据的地址对齐成8的倍数，那么就可以用一个内存操作来读或者写值**
- 否则就可能需要执行两次内存访问，因为对象可能被分放在两个8字节内存块中

**注意：无论数据是否对齐，x86-64硬件都能正确工作**

- 还是建议对齐数据，来提高内存系统的性能
- 对齐原则：任何K字节的基本对象的地址必须是K的倍数

例如

```c
struct S1{
  int i;
  char c;
  int j;
}
```

假设编译器用最小的9字节分配，那么中间就会有1个字节的char，满足不了4个字节的int，所以中间需要补3个字节。**结果整个结构大小就会变成12字节**

假如对齐

```c
struct S2{
  int i;
  int j;
  char c;
}
```

这样子，只要保证结构的起始地址满足4字节对齐要求，我们仍然能保证满足字段i和j的对齐要求

- 但是如果这样声明，``struct S2 d[4]``，还是会有3个字节被浪费掉，没办法

##### 3.10 在机器级程序中将控制与数据结合起来

##### 3.10.1 理解指针

**函数指针**

```c
int (*f)(int*)
```

- 返回值int
- f是函数名
- *f意思是指向f这个函数的指针，也就是函数指针
- (Int*) 表示参数是一个int类型的指针，参数名省略了，没有写出来

- (*f)加括号是防止跟前面的返回值int混淆了

##### 3.10.4 对抗缓冲区溢出攻击

- 栈随机化
  - 地址空间布局随机化（Address-Space Layout Randomization）
  - 每次运行时程序的不同部分，包括程序代码、库代码、栈、全局变量和堆数据，都会被加载到内存的不同区域
  - 这种方法会被暴力破解，在攻击代码前面加很长的nop（no operation），执行这种指令之后，会使程序计数器加1，只要攻击者能够猜到某个地址，然后程序就会执行恶意代码
- 栈破坏检测
  - 在栈帧中任何局部缓冲区与栈状态之间存储一个特殊的金丝雀（canary）值，是在程序每次运行时随机产生的，在恢复寄存器状态之前，程序检测金丝雀值是否被改变，如果被改变了，程序就中止
- 限制可执行代码区域
  - 只有保存编译器产生的代码的那部分内存才是可执行的

### 第四章 处理器体系结构

x86-64有时称为“复杂指令集计算机”（CISC，读作“sisk”）与“精简指令集计算机”（RISC）相对。

##### 4.2.5 存储器和时钟

存储设备都是由同一个时钟控制的，时钟是一个周期性的信号，决定什么时候要把新值加载到设备中

- 时钟寄存器（简称寄存器）存储单个位或字。时钟信号控制寄存器加载输入值
- 随机访问存储器（简称内存）存储多个字，用地址来选择该读或该写哪个字
  - 处理器的虚拟内存系统
  - 寄存器文件

大多数实际系统中，是一个具有双端口的存储器：一个用来读指令，另一个用来读或者写数据

处理器的各个阶段

- 取指（fetch）：取指阶段从内存读取指令字节，地址为程序计数器（PC）的值。
- 译码（decode）：从寄存器文件中读入最多两个操作数，得到值valA和valB。
- 执行（execute）：在执行阶段，算术/逻辑单元（ALU）要么执行指令指明的操作（根据ifun的值），计算内存引用的有效地址，要么增加或减少栈指针。
- 访存（memory）：访存阶段可以将数据写入内存，或者从内存读出数据。
- 写回（write back）：写回阶段最多可以写两个结果到寄存器文件。
- 更新PC（PC update）：将PC设置成下一条指令的地址。

**处理器无限循环，执行这些阶段**

执行流程在书的272页有一个图，SEQ的抽象视图，很直观，描述的就是上面这几个阶段

SEQ的实现包括组合逻辑和两种存储器设备

- 时钟寄存器（程序计数器和条件码寄存器）
- 随机访问存储器（寄存器文件、指令内存和数据内存）

**处理器从来不需要为了完成一条指令的执行而去读由该指令更新了的状态**

**SEQ这种实现方法不能充分利用硬件单元，因为每个单元只在整个时钟周期的一部分时间内才被使用**

#### 4.4 流水线的通用原理

流水线化的一个重要特性就是提高了系统的吞吐量（throughput），也就是单位时间内服务的顾客总数，不过也会轻微的增加延迟（latency），也就是服务一个用户所需要的时间

##### 4.4.1 计算流水线

它是由一些执行计算的逻辑以及一个保存计算结果的寄存器组成的。

时钟信号控制在每个特定的时间间隔加载寄存器。

在现代逻辑设计中，电路延迟以微微秒或皮秒（picosecond，简写成“ps”），也就是10的-12次分秒位单位。

**以每秒千兆条指令（GIPS），也就是每秒十亿条指令，为单位来描述吞吐量**

- 从头到尾执行一条指令所需要的时间称为延迟（latency）

缓慢时钟不会影响流水线的行为，信号传播到流水线寄存器到输入，但是直到时钟上升时才会改变寄存器到状态。

SEQ与SEQ+

- SEQ中，PC计算发生在时钟周期结束的时候，根据当前时钟周期内计算出的信号值来计算PC寄存器的新值
- SEQ+中，创建状态寄存器来保存在一条指令执行过程中计算出来的信号，然后当一个新的时钟周期开始时，这些信号值通过同样的逻辑来计算当前指令的PC

SEQ+的图在书的290页

**数据冒险在书的298页有总结**

##### 4.5.6 异常处理

处理器中很多事情都会导致异常控制流，此时，程序执行的正常流程被破坏掉

**异常可以从内部产生，也可以由外部信号产生**

内部异常

- halt指令
- 有非法指令和功能码组合的指令
- 取指或数据读写试图访问一个非法地址

为了避免异常指令之后的指令更新任何程序员可见的状态，当处于访存或写回阶段中的指令导致异常时，流水线控制逻辑必须禁止更新条件码寄存器或是数据内存。

### 第五章 优化程序性能

编写高效的程序需要做到以下几点

- 第一，我们必须选择一组适当的算法和数据结构
- 第二，我们必须编写出编译器能够有效优化以转换成高效可执行代码的源代码
  - 理解优化编译器的能力和局限性是很重要的

**尽管做了大量的变化，但还是要维护代码一定程度的简洁和可读性**

#### 5.2 表示程序性能

度量标准每元素的周期数（Cycles Per Element，CPE）

#### 5.3 程序示例

使用define定义，然后使用命令行选项，``-O1``进行优化

- 可以显著的提高程序性能——超过两个数量级

#### 5.4 消除循环的低效率

将循环变量条件写外面，不要每次都计算

例如

```c
void combine1(vec_ptr v, data_t *dest){
	long i;
  *dest = IDENT;
  for(i = 0; i < vec_length(v); i++){
    data_t val;
    get_vec_element(v, i, &val);
    *dest = *dest OP val;
  }
}
```

```c
void combine2(vec_ptr v, data_t *dest){
	long i;
	long length = vec_length(v);
  *dest = IDENT;
  for(i = 0; i < length; i++){
    data_t val;
    get_vec_element(v, i, &val);
    *dest = *dest OP val;
  }
}
```

**combine2的效果要比combine1好，仅仅移动计算length的位置，就可以有性能上的提升，如果求长度是一个需要每次遍历的函数，那么这个优化就能起到很大的作用，不需要每次循环都遍历求一次长度**

这个优化是一类常见的优化的一个例子，**称为代码移动（code motion）**

- 优化包括识别要执行多次（例如在循环里）但是计算结果不会改变的计算

#### 5.5 减少过程调用

例如直接取数组下标，每次通过数组下标取指，都会进行一次边界检测，实际上也会影响性能，**影响并不是很大**

```c
data_t *get_vec_start(vec_ptr v){
  return v->data;
}
void combine3(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  data_t *data = get_vec_start(v);
  *dest = IDENT;
  for(i = 0; i < length(); i++){
    *dest = *dest OP data[i];
  }
}
```

事实上，整数求和的性能还略有下降

#### 5.6 消除不必要的内存引用

combine3中的dest是一个指针，所以每次累加求和的时候，这个指针都要加8，累积变量的数值都要从内存读出然后再写入到内存。这样的读写很浪费

```c
void combine3(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  data_t *data = get_vec_start(v);
  data_t acc = IDENT;
  for(i = 0; i < length(); i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

#### 5.7 理解现代处理器

##### 5.7.1 整体操作

超标量：意思是处理器可以在每个时钟周期执行多个操作，而且是乱序的

整个设计有两个主要部分：

- 指令控制单元（Instruction Control Unit，ICU）
  - 负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作
- 执行单元（Execution Unit，EU）
  - 执行上面的操作

ICU从指令高速缓存（instruction cache）中读取指令，指令高速缓存是一个特殊的高速存储器，它包含最近访问的指令。

- ICU会在当前正在执行的指令很早之前取指，这样它才有足够的时间对指令译码，并把操作发送到EU。
- 如果当程序遇到分支时，程序有两个可能的前进方向
  - 一种可能会选择分支，控制被传递到分支目标
  - 另一种，不选择分支，控制被传递到指令序列的下一条指令

**现代处理器采用了一种分支预测的技术，处理器会猜测是否会选择分支，同时还预测分支的目标地址**

使用投机执行（speculative execution）的技术，处理器会开始取出位于它预测的分支会跳到的地方的指令，并对指令译码，甚至在它确定分支预测是否正确之前就开始执行这些操作。

如果过后确定分支预测错误，会将状态重新设置到分支点的状态，并开始取出和执行另一个方向上的指令。标记为取指控制的块，包括分支预测，以完成确定取哪些指令的任务。

**任何对程序寄存器的更新都只会在指令退役时才会发生，只有在处理器能够确信导致这条指令的所有分支都预测正确了，才会这样做**

#### 5.8 循环展开

通过增加每次迭代计算的元素的数量，减少循环的迭代次数

```c
void combine5(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *data = get_vec_start(v);
  data_t acc = IDENT;
  // combine 2 elements at a time
  for(i = 0; i < limit; i+=2){
    acc = (acc OP data[i]) OP data[i+1];
  }
  
  // finish any remaning elements
  for(; i < length; i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

#### 5.9 提高并行性

**程序的性能是受运算单元的延迟限制的**

##### 5.9.1 多个累积变量

将一组合并运算分割成两个或更多的部分，并在最后合并结果来提高性能

感觉这样有点夸张了。。。但是性能确实提高了

```c
void combine6(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *data = get_vec_start(v);
  data_t acc0 = IDENT;
  
  // combine 2 elements at a time
  for(i = 0; i < limit; i+=2){
    acc0 = acc0 OP data[i];
    acc1 = acc1 OP data[i+1];
  }
  
  // finish any remaning elements
  for(; i < length; i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

##### 5.9.2 重新结合变换

另一种打破顺序相关从而使得性能提高到延迟界限之外的方法

```c
void combine6(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *data = get_vec_start(v);
  data_t acc0 = IDENT;
  
  // combine 2 elements at a time
  for(i = 0; i < limit; i+=2){
    acc = acc OP (data[i] OP data[i+1]);
  }
  
  // finish any remaning elements
  for(; i < length; i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

#### 5.11 一些限制因素

关键路径指明了执行该程序所需时间的一个基本的下界

##### 5.11.1 寄存器溢出

循环并行性的好处受汇编代码描述计算的能力限制。

如果我们的并行度p超过了可用的寄存器数量，那么编译器会诉诸溢出（spilling），将某些临时值存放到内存中，通常是在运行时堆栈上分配空间。

##### 5.11.2 分支预测和预测错误处罚

通用规则

- 不要过分关心可预测的分支
- 书写适合用条件传送实现的代码

```c
void minmax1(long a[], long b[], long n){
  long i;
  for(i = 0; i < n; i++){
    if(a[i] > b[i]){
      long t = a[i];
      a[i] = b[i];
      b[i] = t;
    }
  }
}
```

使用条件传送后

```c
void minmax1(long a[], long b[], long n){
  long i;
  for(i = 0; i < n; i++){
    long min = a[i] < b[i] ? a[i] : b[i];
    long max = a[i] < b[i] ? b[i] : a[i];
    a[i] = min;
    b[i] = max;
  }
}
```

#### 5.12 理解内存性能

##### 5.12.1 加载的性能

加载操作的地址只依赖于循环索引``i``，所以加载操作不会成为限制性能的关键路径的一部分

##### 5.12.2 存储的性能

存储操作并不影响任何寄存器值，因此，一系列存储操作不会产生数据相关。

- 只有加载操作会受存储操作结果的影响，因为只有加载操作能从由存储操作写的那个位置读回值

**存储单元包含一个存储缓冲区**，它包含已经被发射到存储单元而又还没有完成的存储操作的地址和数据，这里的完成包括更新数据高速缓存。

- 提供这样一个缓冲区，使得一系列存储操作不必等待每个操作都更新高速缓存就能够执行
- 当一个加载操作发生时，它必须检查存储缓冲区中的条目，看有没有地址相匹配

#### 5.13 应用：性能提高技术

优化程序性能的基本策略

- 高级设计。为遇到的问题选择适当的算法和数据结构
- 基本编码原则。避免限制优化的因素，这样编译器产生高效的代码
  - 消除连续的函数调用。**将计算移到循环外**
  - 消除不必要的内存引用。**引用临时变量来保存中间结果，只有在最后的值计算出来，才将结果存放到数组或全局变量中**
  - 假设没有执行内联替换，则调用消息相当可靠
  - 默认情况下，不会显示对库函数的计时。相反，库函数的时间都被计算到调用它们的函数的时间中

### 第六章 存储器层次结构

存储器系统是一个线性的字节数组，而CPU能够在一个常数时间内访问每个存储器的位置

#### 6.1 存储技术

##### 6.1.1 随机访问存储器

**静态RAM（SRAM）要比动态RAM（DRAM）更快**

- SRAM用来作为高速缓存存储器，既可以在CPU芯片上，也可以在片下
- DRAM用来作为主存以及图形系统的帧缓冲区

**1.静态RAM**

- SRAM将每个位存储在一个双稳态的（bistable）存储器单元里
- 每个单元是用一个六晶体管电路来实现的
- 只要有电，它就会永远地保持它的值

**2.动态RAM**

- DRAM将每个位存储为对一个电容的充电

**4.内存模块**

- DRAM芯片封装在内存模块（memory module）中，它插到主板的扩展槽上
- Core i7，系统使用的240个引脚的双列直插内存模块，它以64位为块传送数据到内存控制器和从内存控制器传出数据

**6.非易失性存储器**

**如果断电，DRAM和SRAM会丢失它们的信息**

非易失性存储器，一般都是只读存储器

**7.访问主存**

数据流通过称为总线（bus）的共享电子电路在处理器和DRAM主存之间来来回回

每次CPU和主存之间的数据传送都是通过一系列步骤来完成的，**这些步骤称为总线事务**

- 读事务从主存传送数据到CPU
- 写事务从CPU传送数据到主存

**总线是一组并行的导线，能携带地址、数据和控制信号**

##### 6.1.2 磁盘存储

**1.磁盘构造**

磁盘是由盘片构成的

- 每个盘片有两面或者称为表面，表面覆盖着磁性记录材料
- 盘片中央有一个可以旋转的主轴，它使得盘片以固定的旋转速率旋转，**通常是5400-15000转每分钟（Revolution Per Minuete，RPM）**
- 磁盘通常包含一个或多个这样的盘片，并封装在一个密封的容器内

磁盘制造商通常用术语柱面来描述多个盘片驱动器的构造

- 柱面是所有盘片表面上到主轴中心的距离相等的磁道的集合

**2.磁盘容量**

一个磁盘上可以记录的最大位数称为它的最大容量，或者简称容量

磁盘容量是由以下技术因素决定的

- 记录密度：磁道一英寸的段中可以放入的位数
- 磁道密度：从盘片中心出发半径上一英寸的段内可以有的磁道数
- 面密度：记录密度与磁道密度的乘积

**3.磁盘操作**

磁盘用读/写头来读写存储在磁性表面的位，而读写头连接到一个传动臂一端

- 通过沿着半径轴前后移动这个传动臂，驱动器可以将读/写头定位在盘面上的任何磁道上。这样的机械运动称为寻道（seek）

**在任何时刻，所有的读/写都位于同一个柱面上**

**磁盘以扇区大小的块来读写数据，对扇区的访问时间有三个主要的部分：**

- 寻道时间
- 旋转时间
- 传送时间

**为什么实际磁盘容量比购买的容量要小？**

- 磁盘控制器必须对磁盘进行格式化，然后才能在该磁盘上存储数据
- 格式化包括用标识扇区的信息填写扇区之间的间隙，标识出表面有故障的柱面并且不使用它们，**以及在每个区中预留出一组柱面作为备用**，如果区中一个或多个柱面在磁盘使用过程中坏掉了，就可以使用这些备用的柱面
- **因为存在这些备用的柱面，所以磁盘制造商所说的格式化容量比最大容量要小**

**6.访问磁盘**

CPU使用一种称为内存映射I/O的技术来向I/O设备发射命令

在使用内存映射I/O的系统中，地址空间中有一块地址是为与I/O设备通信保留的

- 每个这样的地址称为一个I/O端口（I/O port）

在磁盘控制器收到来自CPU的读命令后，它将逻辑块号翻译成一个扇区地址，读该扇区的内容，然后将这些内容直接传送到主存，不需要CPU的干涉

设备可以自己执行读或者写总线事务而不需要CPU干涉读过程，称为直接内存访问（Direct Memory Access，DMA）

- 这种数据传送称为DMA传送

- 在DMA传送完成，磁盘扇区内容被安全地存储在主存中以后，磁盘控制器通过给CPU发送一个中断信号来通知CPU。
- **基本思想是中断会发信号到CPU芯片的一个外部引脚上，这会导致CPU暂停它当前正在做的工作，跳转到一个操作系统例程**，这个程序会记录I/O已经完成，然后将控制返回到CPU被中断的地方

##### 6.1.3 固态硬盘

固态硬盘（Solid State Disk，SSD）是一种基于闪存的存储技术

SSD封装插到I/O总线上标准硬盘插槽中，行为就和其他硬盘一样，处理来自CPU的读写逻辑磁盘块的请求

一个SSD封装由一个或多个闪存芯片和闪存翻译层组成，闪存芯片替代传统旋转磁盘中的机械驱动器，而闪存翻译层是一个硬件/固件设备，扮演与磁盘控制器相同的角色，将对逻辑块的请求翻译成对底层物理设备的访问

#### 6.2 局部性

局部性有两种不同的形式：时间局部性和空间局部性

##### 6.2.1 对程序数据引用的局部性

好的局部性程序

```c
int sumarrayrows(int a[M][N]){
  int i, j, sum = 0;
  for(i = 0; i < M; i++){
    for(j = 0; j < N; j++){
      sum += a[i][j];
    }
  }
  return sum;
}
```

坏的局部性

```c
int sumarraycols(int a[M][N]){
  int i, j, sum = 0;
  for(j = 0; j < M; j++){
    for(i = 0; i < N; i++){
      sum += a[i][j];
    }
  }
  return sum;
}
```

##### 6.2.2 局部性小结

评价局部性的一些简单原则

- 重复引用相同变量的程序有良好的时间局部性
- 对于具有步长为k的引用模式的程序，步长越小，空间局部性越好
- 对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好

#### 6.4 高速缓存存储器

##### 6.4.2 直接映射高速缓存

高速缓存确定一个请求是否命中，然后抽取出被请求的字的过程

- 组选择
- 行匹配
- 字抽取

**高速缓存行、组和块有什么区别？**

- 块是一个固定大小的信息包，在高速缓存和主存（或下一层高速缓存）之间来回传送
- 行是高速缓存中的一个容器，存储块以及其他信息（例如有效位和标记位）
- 组是一个或多个行的集合。直接映射高速缓存中的组只由一行组成。组相联和全相联高速缓存中的组是由多个行组成的

**在直接映射高速缓存中，组和行实际上是等价的，在相联高速缓存中，组和行是很不一样的，这两个词不能互换使用**

#### 6.5 编写高速缓存友好的代码

基本方法

- 让最常见的情况运行得快
- 尽量减小每个循环内部的缓存不命中数量

### 第七章 链接

链接是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行

链接可以执行于编译时，也就是在源代码被翻译成机器代码时；也可以执行于运行时，也就是由应用程序来执行

 #### 7.1 编译器驱动程序

main.c

```c
int sum(int *a, int n);
int array[2] = {1, 2};
int main(){
  int val = sum(array, 2);
  return val;
}
```

sum.c

```c
int sum(int *a, int n){
  int i, s = 0;
  for(i = 0; i < n; i++){
    s += a[i];
  }
  return s;
}
```

调用GCC驱动程序``gcc -Og -o prog main.c sum.c``

- 生成-o文件之后，再运行链接程序ld，将main.o和sum.o以及一些必要的系统目标文件组合起来，创建一个可执行目标文件

#### 7.4 可重定位目标文件

不同节的位置和大小是由节头部表描述的，其中目标文件中每个节都有一个固定大小的条目（entry）

典型的ELF可重定位目标文件包含下面几个节

- .text：已编译程序的机器代码
- .rodata：只读数
- .data：已初始化的全局和静态C变量
- .bss：未初始化的全局和静态C变量
- .symtab：一个符号表，它存放在程序中定义和引用的函数和全局变量的信息
- .rel.text：一个.text节中位置的列表，当链接器把这个目标文件和其他文件组合时，需要修改这些位置
- .rel.data：被模块引用或定义的所有全局变量的重定位信息
- .debug：一个调试符号表，其条目是程序中定义的局部变量和类型定义，程序中定义和引用的全局变量，以及原始的C源文件
- .line：原始C源程序中的行号和.text节中机器指令之间的映射
- .strtab：一个字符串表，其内容包括.symtab和.debug节中的符号表，以及节头部中的节名字

**为什么未初始化的数据称为.bss**

- 起始于IBM704汇编语言中“块存储开始（Block Storage Start）”指令的首字母缩写
- .data和.bss节之间区别的简单方法是把"bss"看成是“更好地节省空间（Better Save Space）的缩写

**定义为带有static属性的本地过程变量是不在栈中管理的。相反，编译器在.data或.bss中为每个定义分配空间，并在符号表中创建一个有唯一名字的本地链接器符号**

COMMON和.bss的区别

- COMMON：未初始化的全局变量
- .bss：未初始化的静态变量，以及初始化为0的全局或静态变量

#### 7.6 符号解析

链接器解析符号引用的方法是将每个引用与它输入的可重定位目标文件的符号表中的一个确定的符号定义关联起来。

##### 7.6.1 链接器如何解析多重定义的全局符号

Linux链接器使用下面的规则来处理多重定义的符号名

- 规则1：不允许有多个同名的强符号
- 规则2：如果有一个强符号和多个弱符号同名，那么选择强符号
- 规则3：如果有多个弱符号同名，那么从这些弱符号中任意选择一个

``gcc foo.c bar.c``

两个main，会报错，main是强符号

```c
// foo.c
int main(){}
// bar.c
int main(){}
```

强符号x被定义了两次

```c
// foo.c
int x = 123;
// bar.c
int x = 123;
```

一强一弱，不报错

```c
// foo.c
int x = 123;
// bar.c
int x;
```

两个弱，不报错，但是这种会引起歧义，如果后续修改了这个值就很难控制了

```c
// foo.c
int x;
// bar.c
int x;
```

类型不同也是，链接的时候只会warning，并不是error

```c
// foo.c
int x;
// bar.c
double x;
```

##### 7.6.2 与静态库链接

在链接时，链接器只复制被程序引用的目标模块，这就减少了可执行文件在磁盘和内存中的大小

在Linux中，静态库以一种称为存档（archive）的特殊文件格式存放在磁盘中

- 存档文件是一组连接起来的可重定位目标文件的集合，有一个头部用来描述每个成员目标文件的大小和位置
- 存档文件名由后缀.a标识

#### 7.8 可执行目标文件

可执行目标文件的格式类似于可重定位目标文件的格式

ELF头描述文件的总体格式，它还包括程序的入口点，也就是当程序运行时要执行的第一条指令的地址。

**.text、.rodata和.data节与可重定位目标文件中的节是相似的，除了这些节已经被重定位到它们最终到运行时内存地址以外，.init节定义了一个小函数，叫做_init，程序的初始化代码会调用它**

ELF可执行文件被设计得很容易加载到内存，可执行文件的连续的片（chunk）被映射到连续的内存段

#### 7.9 加载可执行文件

在Linux shell命令行中输入运行的名字

```bash
linux> ./prog
```

因为prog不是一个内置的shell命令，所以shell会认为prog是一个可执行目标文件，通过调用某个驻留在存储器中称为加载器（loader）的操作系统代码来运行它

**加载器将可执行目标文件中的代码和数据从磁盘复制到内存中，然后通过跳转到程序的第一条指令或入口点来运行该程序。**

- 这个将程序复制到内存并运行的过程叫做加载

**加载器实际是如何工作的？**

- Linux系统中的每个程序都运行在一个进程上下文中，有自己的虚拟地址空间。
- 当shell运行一个程序时，父shell进程生成一个子进程，它是父进程的一个复制。
- 子进程通过execve系统调用启动加载器。
- 加载器删除子进程现有的虚拟内存段，并创建一组新的代码、数据、堆和栈段。
- 新的栈和堆段被初始化为零。
- 通过将虚拟地址空间中的页映射到可执行文件的页大小的片（chunk），新的代码和数据段被初始化为可执行文件的内容。
- 最后，加载器跳转到_start地址，它最终会调用应用程序的main函数。
- 除了一些头部信息，在加载过程中没有任何从磁盘到内存的数据复制。
- 直到CPU引用一个被映射的虚拟页时才会进行复制，此时，操作系统利用它的页面调度机制自动将页面从磁盘传送到内存

#### 7.10 动态链接共享库

**静态库缺点：静态库和所有的软件一样，需要定期维护和更新。**

共享库（shared library）是致力于解决静态库缺陷的一个现代创新产物。

共享库是一个目标模块，在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。

- **这个过程称为动态链接，是由一个叫做动态链接器的程序来执行的**
- 微软的操作系统大量地使用了共享库，它们称为DLL（动态链接库）

对于一个库只有一个.so文件。所有引用该库的可执行目标文件共享这个.so文件中的代码和数据，而不是像静态库的内容那样被复制和嵌入到引用它们的可执行的文件中

**在内存中，一个共享库的.text节的一个副本可以被不同的正在运行的进程共享**

#### 7.11 从应用程序中加载和链接共享库

将每个生成动态内容的函数打包在共享库中

- 当一个来自Web浏览器的请求到达时，服务器动态地加载和链接适当的函数，然后直接调用它，而不是使用fork和execve在子进程的上下文中运行函数
- 函数会一直缓存在服务器的地址空间中，所以只要一个简单的函数调用的开销就可以处理随后的请求了
- **在运行时无需停止服务器，就可以更新已存在的函数，以及添加新的函数**

Linux系统为动态链接器提供了一个简单的接口，运行应用程序在运行时加载和链接共享库

```c
#include <dlfcn.h>
void *dlopen(const char *filename, int flag);
返回：若成功则为指向句柄的指针，若出错则为NULL
```

```c
#include <dlfcn.h>
void *dlsym(void *handle, char *symbol);
返回：若成功则为指向句柄的指针，若出错则为NULL
```

dlsym函数的输入是一个指向前面已经打开了的共享库的句柄和一个symbol名字

如果没有其他共享库还在使用这个共享库，dlcloes函数就卸载该共享库

```c
#include <dlfcn.h>
int dlclose(void *handle);
返回：成功为0，出错为-1
```

```c
#include <dlfcn.h>
const char *dlerror(void);
返回：如果前面堆dlopen、dlsym或dlclose的调用失败，则为错误消息，如果前面的调用成功，则为NULL
```

#### 7.12 位置无关代码

共享库的一个主要目的就是允许多个正在运行的进程共享内存中相同的库代码，因而节约宝贵的内存资源

现代系统以这样一种方式编译共享模块的代码段，使得可以把它们加载到内存的任何位置而无需链接器修改。

- 使用这种方法，无限多个进程可以共享一个共享模块的代码段段单一副本。（每个进程仍然会有它自己的读/写数据块）

**可以加载而无需重定位的代码称为位置无关代码（Position-Independent Code，PIC）。用户对GCC使用-fpic选项指示GNU编译系统生成PIC代码。共享库的编译必须总是使用该选项**

#### 7.13 库打桩机制

库打桩：允许我们截获对共享库函数的调用，取而代之执行自己的代码

使用打桩机制，可以追逐对某个特殊库函数的调用次数，验证和追逐它的输入和输出值，或者甚至把它替换成一个完全不同的实现

基本思想

- 给定一个需要打桩的目标函数，创建一个包装函数，它的原型与目标函数完全一样
- 使用某种特殊的打桩机制，你就可以欺骗系统调用包装函数而不是目标函数了
- 包装函数通常会执行它自己的逻辑，然后调用目标函数，再将目标函数的返回值传递给调用者

### 第八章 异常控制流

现代系统通过使控制流发生突变来对这些情况做出反应。

- 称为异常控制流（Exceptional Control Flow，ECF）

理解ECF很重要，有很多原因

- 理解ECF将帮助你理解重要的系统概念
- 理解ECF将帮助你理解应用程序是如何与操作系统交互的
- 理解ECF将帮助你编写有趣的新应用程序
- 理解ECF将帮助你理解并发
- 理解ECF将帮助你理解软件异常如何工作

#### 8.1 异常

**异常时异常控制流的一种形式，它一部分由硬件实现，一部分由操作系统实现**

异常的剖析

- 处理器状态中的变化（事件）触发从应用程序到异常处理程序到突发的控制转移（异常）
- 在异常处理程序完成处理后，它将控制返回给被中断的程序或者终止

**在任何情况下，当处理器检测到有事件发生时，它就会通过一张叫做异常表（exception table）的跳转表（系统启动时分配初始化的），进行一个间接过程调用（异常），到一个专门设计用来处理这类事件的操作系统子程序（异常处理程序（exception handler））**

##### 8.1.1 异常处理

系统中可能的每种类型的异常都分配了一个唯一的非负整数的异常号

- 其中一些号码是由处理器的设计者分配的，其他号码是由操作系统内核的设计者分配的
- 前者的示例包括被零除、缺页、内存访问违例、断点以及算术运算溢出
- 后者的示例包括系统调用和来自外部I/O设备的信号

**异常表的起始地址放在一个叫做异常表基址寄存器的特殊CPU寄存器**

异常类似于过程调用，也有一些重要的不同之处

- 过程调用时，在跳转到处理程序之前，处理器将返回地址压入栈中。然而，根据异常的类型，返回地址要么是当前指令（当事件发生时正在执行的指令），要么是下一条指令（如果事件不发生，将会在当前指令后执行的指令）
- 处理器也把一些额外的处理器状态压到栈里，在处理程序返回时，重新开始执行被中断的程序会需要这些状态
- 如果控制从用户程序转移到内核，所有这些项目都被压到内核栈中，而不是压到用户栈中
- 异常处理程序运行在内核模式下，这意味着它们对所有的系统资源都有完全的访问权限

**一旦硬件触发了异常，剩下的工作就是由异常处理程序在软件中完成**

##### 8.1.2 异常的类别

**1.中断**

- 中断是异步发生的，是来自处理器外部的I/O设备的信号的结果

**2.陷阱和系统调用**

- 陷阱是有意的异常，是执行一条指令的结果
- **陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用**
- 普通函数在用户态，系统调用在内核态

**3.故障**

- 故障由错误情况引起，它可能能够被故障处理程序修正
- 经典的故障示例是缺页异常，当指令引用一个虚拟地址，而与该地址相对应的物理页面不在内存中，因此必须从磁盘中取出时，就会发生故障

**4.终止**

- 终止是不可恢复的致命错误造成的结果，通常是一些硬件错误，比如DRAM或者SRAM位被损坏时发生的奇偶错误
- 终止处理程序从不将控制返回给应用程序

##### 8.1.3 Linux/x86-64系统中的异常

**1.Linux/x86-64故障和终止**

- 除法错误。当除零时，或者当一个除法指令的结果对于目标操作数来说太大了时候，就会发生除法错误。**错误报告：浮点异常（Floating exception）**
- 一般保护故障。通常是因为一个程序引用了一个未定义的虚拟内存区域，或者因为程序试图写一个只读的文本段。**错误报告：段故障（Segmentation fault）**
- 缺页。处理程序将适当的磁盘上虚拟内存的一个页面映射到物理内存的一个页面，然后重新执行这条产生故障的指令。
- 机器检查。在导致故障的指令执行中检测到致命的硬件错误时发生的。

**2.Linux/x86-64系统调用**

- 每个系统调用都有一个唯一的整数号，对应于一个到内核中跳转表的偏移量（注意：这个跳转表和异常表不一样）
- 系统调用是通过一条称为syscall的陷阱指令来提供的
- 所有到Linux系统调用的参数都是通过通用寄存器而不是栈传递的

#### 8.2 进程

异常是允许操作系统内核提供进程（process）概念的基本构造块

进程的经典定义就是一个执行中程序的实例。系统中的每个程序都运行在某个进程的上下文（context）中。

- 上下文是由程序正确运行所需的状态组成的
- 这个状态包括存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合

##### 8.2.1 逻辑控制流

进程为每个程序提供了一种假象，好像程序在独占地使用处理器。

CPU会周期性地停顿，每次CPU停顿，它随后会继续执行我们的程序，并不改变程序内存位置或寄存器的内容

##### 8.2.2 并发流

多个流并发地执行的一般现象被称为并发（concurrency）

一个进程和其他进程轮流运行的概念称为多任务（multitasking）

一个进程执行它的控制流的一部分的每一时间段叫做时间片（time slice）

多任务也叫做时间分片（time slicing）

**注意，并发流的思想与流运行的处理器核数或者计算机无关**

如果两个流在时间上重叠，那么它们就是并发的，即使它们是运行在同一个处理器上

##### 8.2.4 用户模式和内核模式

一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中的任何内存位置

没有设置模式位时，进程就运行在用户模式中。

- 用户模式中的进程不允许执行特权指令（privileged instruction），比如停止处理器、改变模式位，或者发起一个I/O操作

**用户程序必须通过系统调用接口间接地访问内核代码和数据**

运行应用程序代码的进程初始化是在用户模式中的。进程从用户模式变为内核模式的唯一方法是通过诸如中断、故障或者陷入系统调用这样的异常。

- 当异常发生时，控制传递到异常处理程序，处理器将模式从用户模式变为内核模式
- 处理程序运行在内核模式中，当它返回到应用程序代码时，处理器就把模式从内核模式改回到用户模式

**Linux提供了一种聪明的机制，叫做/proc文件系统，它允许用户模式进程访问内核数据结构的内容**

- /proc文件系统将许多内核数据结构的内容输出为一个用户程序可以读的文本文件的层次结构
- 可以使用/proc文件系统找出一般的系统属性，比如CPU类型（/proc/cpuinfo）
- 或者某个特殊的进程使用的内存段（/proc/<process-id>/maps）
- 2.6版本的Linux内核引入/sys文件系统，它输出关于系统总线和设备的额外的低层信息

##### 8.2.5 上下文切换

操作系统内核使用一种称为上下文切换的较高层形式的异常控制流来实现多任务

**内核为每个进程维持一个上下文**

- 上下文就是内核重新启动一个被抢占的进程所需的状态
- 它由一些对象的值组成，这些对象包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构，比如描述地址空间的页表，包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表

**在进程执行的某些时刻，内核可以决定抢占当前进程，并重新开始一个先前被抢占了的进程。这种决策叫做调度，是由内核中称为调度器的代码处理的**

**上下文切换**

- 保存当前进程的上下文
- 恢复某个先前被抢占的进程被保存的上下文
- 将控制传递给这个新恢复的进程

发生上下文切换的情况：当内核代表用户执行系统调用时、中断等等

#### 8.3 系统调用错误处理

可以使用错误包装函数来简化代码

```c
if((pid = fork()) < 0)
{
  fprintf(stderr, "fork error:%s\n", strerror(errno));
  exit(0);
}
```

strerror函数返回一个字符串，所以可以进行包装一下

```c
void unix_error(char *msg)
{
  fprintf(stderr, "%s:%s\n", msg, strerror(errno));
}
```

```c
if((pid = fork()) < 0)
{
  unix_error("fork error");
}
```

对fork调用从4行缩减到2行，而且可读性也提高了，我觉得行

#### 8.4 进程控制

##### 8.4.1 获取进程ID

每个进程都有一个唯一的正数（非零）进程ID（PID）

```c
#include<sys/types.h>
#include<unistd.h>
pid_t getpid(void);
pid_t getppid(void);
```

##### 8.4.2 创建和终止进程

进程总是处于下面三种状态之一

- 运行。进程要么在CPU上执行，要么在等待被执行且最终会被内核调度
- 停止。进程的执行被挂起（suspended），且不会被调度。当收到SIGSTOP、SIGTSTP、SIGTTIN或者SIGTTOU信号时，进程就停止，并且保持停止直到它收到一个SIGCONT信号，在这个时刻，进程再次开始运行
- 终止。进程永远地停止了
  - 收到一个信号，该信号的默认行为时终止进程
  - 从主程序返回
  - 调用exit函数

##### 8.4.3 回收子进程

当父进程回收已终止的子进程时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程，从此时开始，该进程就不存在了。

**一个终止了但还未被回收的进程称为僵尸进程（zombie）**

如果父进程没有回收它的僵死子进程就终止了，那么内核会安排init进程去回收它们

##### 8.4.4 让进程休眠

sleep函数将一个进程挂起一段指定的时间

```c
#include <unistd.h>
unsigned int sleep(unsigned int secs);
返回：还要休眠的秒数
```

pause函数，让调用函数休眠，直到该进程收到一个信号

```c
#include <unistd.h>
int pause(void);
总是返回-1
```

##### 8.4.5 加载并运行程序

execve函数在当前进程的上下文中加载并运行一个新程序，这个函数在docker和k8s中都有用到

```c
#include <unistd.h>
int execve(const char *filename, const char *argv[], const char *envp[]);
如果成功，则不返回，如果错误，则返回-1
```

**程序与进程**

程序是一堆代码和数据；程序可以作为目标文件存在与磁盘上，或者作为段存在于地址空间中。

进程是执行中程序的一个具体的实例；**程序总是运行在某个进程的上下文中**

**fork函数在新的子进程中运行相同的程序，新的子进程是父进程的一个复制品**

**execve函数在当前进程的上下文中加载病运行一个新的程序。它会覆盖当前进程的地址空间，但并没有创建一个新的进程**

- 新的程序仍然有相同的PID，并且继承了调用execve函数时已打开的所有文件描述符

#### 8.5 信号

一个信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件。

每种信号类型都对应某种系统事件。底层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。

信号提供了一种机制，通知用户进程发生了这些异常

- 如果一个进程试图除以0，那么内核就发送给它一个SIGFPE信号（号码8）
- 如果一个进程执行一条非法指令，那么内核就发送给它一个SIGILL指令（号码4）
- 如果进程进行非法内存引用，内核就发送给它一个SIGSEGV信号（号码11）
- 当进程在前台运行，然后按ctrl c，内核会发送一个SIGINT信号（号码2）给这个前台进程组中的每个进程
- 一个进程可以通过向另一个进程发送一个SIGKILL信号（号码9）强制终止它
- 当一个子进程终止或者停止时，内核会发送一个SIGCHLD信号（号码17）给父进程

##### 8.5.1 信号术语

传送一个信号到目的进程是由两个不同步骤组成

- 发送信号
  - 两个原因：
    - 内核检测到一个系统事件
    - 一个进程调用了kill函数。一个进程可以发送信号给自己
- 接收信号

**一个发出而没有被接收到信号叫做待处理信号（pending signal）**

在任何时刻，一种类型至多只会有一个待处理信号。

- 如果一个进程有一个类型为k的待处理信号，那么任何接下来发送到这个进程的类型为k的信号都不会排队等待；**它们只是被简单地丢弃**
- 一个进程可以有选择性地阻塞接收某种信号，当一种信号被阻塞时，它仍可以被发送，但是产生的待处理信号不会被接收，直到进程取消对这种信号的阻塞

内核为每个进程在pending位向量中维护着待处理信号的集合，而在blocked位向量中维护着被阻塞的信号集合

**只要传送了一个类型为k的信号，内核就会设置pending中的第k位，而只要接收了一个类型为开端信号，内核就会清除pending中的第k位**

##### 8.5.2 发送信号

Unix系统提供了大量向进程发送信号的机制。所有这些机制都是基于进程组（process group）这个概念的

1. 进程组
2. 用/bin/kill程序发送信号。 /bin/kill -9 pid
3. 从键盘发送信号。ls | sort
4.  用kill函数发送信号
5. 用alarm函数发送信号

##### 8.5.3 接收信号

当内核把进程p从内核模式切换到用户模式时，它会检查进程p的未被阻塞的待处理信号的集合（pending & ～blocked）。

- 如果这个集合为空（通常情况下），那么内核将控制传递到p的逻辑控制流中的下一条指令
- 如果是非空的，那么内核选择集合中的某个信号k（通常是最小的k），并且强制p接收信号k

**信号处理程序可以被其他信号处理程序中断**

- 经典的ctrl c结束

##### 8.5.4 阻塞和解除阻塞信号

SIG_BLOCK：把set中的信号添加到blocked中（blocked=blocked ｜ set）

SIG_UNBLOCK：从blocked中删除set中的信号（blocked=blocked & ～set）

SIG_SETMASK：block=set

##### 8.5.5 编写信号处理程序

**1.安全的信号处理**

- 信号处理程序很麻烦是因为它们和主程序以及其他信号处理程序并发地运行

**处理程序要尽可能简单**

**在处理程序中只调用异步信号安全的函数**

- 异步信号安全的函数能够被信号处理程序安全地调用
- 要么它是可重入的，要么它不能被信号处理程序中断

**信号处理程序中产生输出唯一安全的方法是使用write函数，调用printf或sprintf是不安全的。也可以使用SIO（安全的I/O）包**

**2.正确的信号处理**

**未处理的信号是不会排队的，如果信号被阻塞了，那么后面再来的这个信号就直接丢弃了**

如果存在一个未处理的信号就表明至少有一个信号到达了

**不可以用信号来对其他进程中发生的事情计数**

### 第九章 虚拟内存

虚拟内存提供了三个重要的能力

- 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存
- 它为每个进程提供了一致的地址空间，从而简化了内存管理
- 它保护了每个进程的地址空间不被其他进程破坏

#### 9.1 物理和虚拟寻址

计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组。

每字节都有一个唯一的物理地址（Physical Address，PA）

CPU访问内存的最自然的方式就是使用物理地址。称为物理寻址

**现代处理器使用的是一种称为虚拟寻址的寻址形式**

- CPU通过生成一个虚拟地址（Virtual Address，VA）来访问主存
- 这个虚拟地址在被送到内存之前先转换成适当的物理地址
- 将一个虚拟地址转换为物理地址的任务叫做地址翻译

地址翻译需要CPU硬件和操作系统之间的紧密合作。

CPU芯片上叫做内存管理单元（Memory Management Unit，MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理

#### 9.2 地址空间

地址空间是一个非负整数地址的有序集合

在一个带虚拟内存的系统中，CPU从一个有N=2的n次方个地址的地址空间中生成虚拟地址，这个地址空间称为虚拟地址空间。n是机器的位数，例如32位或者64位

**一个地址空间的大小是由表示最大地址所需要的位数来描述的**

地址空间的概念很重要，它清楚地区分了数据对象（字节）和它们的属性（地址）

- 允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间

**主存中的每个字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址**

#### 9.3 虚拟内存作为缓存的工具

**虚拟内存被组织为一个由存放在磁盘上的N个连续的字节大小的单元组成的数组**

- 每个字节都有一个唯一的虚拟地址，作为数组的索引。
- 磁盘上数组的内容被缓存在主存中
- VM系统通过将虚拟内存分割，称为虚拟页（Virtual Page，VP）。每个虚拟页的大小固定来处理问题。
  - 每个虚拟页的大小为P=2的p次方字节
  - 物理内存被分割为物理页（Physical Page，PP），大小也为P字节（物理页也称为页帧（page frame））

在任意时刻，虚拟页面的集合都分为三个不相交的子集

- 未分配的：VM系统还未分配（或者创建）的页。不占用任何磁盘空间
- 缓存的：当前已缓存在物理内存中的已分配页
- 未缓存的：未缓存在物理内存中已分配页

##### 9.3.1 DRAM缓存的组织结构

因为对磁盘的访问时间很长，DRAM缓存总是使用写回，而不是直写

##### 9.3.1 页表

虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在DRAM中的某个地方

- 如果是，系统还必须确定这个虚拟页存放在哪个物理页中
- 如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到DRAM中，替换这个牺牲页

**每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表**

操作系统负责维护页表的内容，以及在磁盘与DRAM之间来回传送页

**页表是一个页表条目（Page Table Entry，PTE）的数组**

- 虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个PTE

假设每个PTE是由一个有效位（valid bit）和一个n位地址字段组成的

- 有效位表明了该虚拟页当前是否被缓存在DRAM中
- 如果设置了有效位，那么地址字段就表示DRAM中相应的物理页的起始位置，这个物理页中缓存了该虚拟页
- 如果没有设置有效位，那么一个空地址表示这个虚拟页还未被分配。否则，这个地址就指向该虚拟页在磁盘上的起始位置

##### 9.3.4 缺页

DRAM缓存不命中称为缺页（page fault）

在虚拟内存的习惯说法中，块被称为页

在磁盘和内存之间传送页的活动叫做交换（swapping）或者页面调度（paging）

- 页从磁盘换入（或者页面调入）DRAM和从DRAM换出（或者页面调出）磁盘

当有不命中发生时，才换入页面调这种策略称为按需页面调度（demand paging）

#### 9.4 虚拟内存作为内存管理的工具

操作系统为每个进程提供了一个独立的页表，也就是一个独立的虚拟地址空间

**注意：多个虚拟页面可以映射到同一个共享物理页面上**

#### 9.5 虚拟内存作为内存保护的工具

不允许一个用户进程修改它的只读代码段。

不允许它读或修改任何内核中的代码和数据结构。

不允许它读或者写其他进程的私有内存。

不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）

**地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每次CPU生成一个地址时，地址翻译硬件都会读一个PTE，所以通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单**

- 如果有一条指令违反了相关设置的许可条件，CPU会触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。**Linux shell一般将这种异常报告为“段错误”**

#### 9.6 地址翻译

页表基址寄存器（Page Table Base Register，PTBR）指向当前页表

n位的虚拟地址包含两个部分：

- 一个p位的虚拟页面偏移（Virtual Page Offset，VPO）
- 一个（n-p）位的虚拟页号（Virtual Page Number，VPN）

##### 9.6.1 结合高速缓存和虚拟内存

地址翻译发生在高速缓存查找之前。

**注意：页表条目可以缓存，就像其他的数据字一样**

##### 9.6.2 利用TLB加速地址翻译

每次CPU产生一个虚拟地址，MMU就必须查阅一个PTE，以便将虚拟地址翻译为物理地址。**在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个周期**

翻译后备缓冲器（Translation Lookaside Buffer，TLB）

TLB是一个小的、虚拟寻址的缓存，其中每一行都保存着一个由单个PTE组成的块。

TLB通常有高度的相联度。用于组选择和行匹配的索引和标记字段是从虚拟地址中的虚拟页号中提取出来的

TLB命中的步骤

- 第一步：CPU产生一个虚拟地址
- 第二步和第三步：MMU从TLB中取出相应的PTE
- 第四步：MMU将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存
- 第五步：高速缓存/主存将所请求的数据字返回给CPU

**当TLB不命中时，MMU必须从L1缓存中取出相应的PTE，新取出的PTE存放在TLB中，可能会覆盖一个已经存在的条目**

##### 9.6.3 多级页表

用来压缩页表的常用方法是使用层次结构的页表。

一级页表中的每个PTE负责映射虚拟地址空间中一个4MB的片（chunk），这里每一片都是由1024个连续的页面组成的。

二级页表中的每个PTE都负责映射一个4KB的虚拟内存页面，就像我们查看只有一级的页表一样。**注意，使用4字节的PTE，每个一级和二级页表都是4KB字节，这刚好和一个页面的大小是一样的**

这种方法从两个方面减少了内存要求

- 第一，如果一级页表中的一个PTE是空的，那么相应的二级页表就根本不会存在。这代表着一种巨大的潜在节约，因为对于一个典型的程序，4GB的虚拟地址空间的大部分都会是未分配的。
- 第二，只有一级页表才需要总是在主存中；虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中

##### 9.7.2 Linux虚拟内存系统

Linux为每个进程维护了一个单独的虚拟地址空间。

**内核虚拟内存位于用户栈之上**

- 包含内核中的代码和数据结构
- 某些区域被映射到所有进程共享的物理页面

内核虚拟内存的其他区域包含每个进程都不相同的数据。比如说，页表、内核在进程的上下文中执行代码时使用的栈，以及记录虚拟地址空间当前组织的各种数据结构

**1.Linux虚拟内存区域**

Linux将虚拟内存组织成一些区域（也叫做段）的集合。一个区域（area）就是已经存在着的（已分配的）虚拟内存的连续片（chunk），这些页是以某种方式相关联的。

**区域的概念很重要，因为它允许虚拟地址空间有间隙。**

- 内核不用记录那些不存在的虚拟页，而这样的页也不占用内存、磁盘或者内核本身中的任何额外资源

**2.Linux缺页异常处理**

如果缺页是合法的，会选择一个牺牲页面，如果这个牺牲页面被修改过，那么就将它交换出去，换入新的页面并更新页表。当缺页处理程序返回时，CPU重新启动引起缺页的指令，这条指令将再次发送A到MMU。这次，MMU就能正常地翻译A，而不会再产生缺页中断了。

#### 9.8 内存映射

Linux通过将一个虚拟内存区域与一个磁盘上的对象关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射（memory mapping）

虚拟内存区域可以映射到两种类型的对象的一种

- Linux文件系统中的普通文件
- 匿名文件

##### 9.8.1 再看共享对象

一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象。

如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于那些页把这个共享对象映射到它们虚拟内存的其他进程而言，也是可见的。**而且，这些变化也会反映在磁盘上的原始对象中**

私有对象使用的一种叫做写时复制（copy-on-write）的巧妙技术被映射到虚拟内存中

- 私有对象开始生命周期的方式基本上与共享对象的一样，在物理内存中只保存有私有对象的一份副本

##### 9.8.2 再看fork函数

当fork函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的PID。

为了给这个新进程创建虚拟内存，它创建了当前进程的mm_struct、区域结构和页表的原样副本。它将两个进程中的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时复制。

当fork在新进程中返回时，新进程现在的虚拟内存刚好和调用fork时存在的虚拟内存相同。当这两个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面，因此，也就为每个进程保持了私有地址空间的抽象概念

##### 9.8.3 再看execve函数

运行步骤

- 删除已存在的用户区域。删除当前进程虚拟地址的用户部分中的已存在的区域结构
- 映射私有区域。为新程序的代码、数据、bss和栈区域创建新的区域结构。这些都是私有的，写时复制的
- 映射共享区域。
- 设置程序计数器。设置当前进程上下文中的程序计数器，使之指向代码区域的入口点

下次调度这个进程时，它将从这个入口点开始执行

#### 9.9 动态内存分配

动态内存分配器维护着一个进程的虚拟内存区域，称为堆（heap）

分配器有两种基本风格，都要求应用显式地分配块，不同之处在于由哪个实体来负责释放已分配的块

- 显式分配器（explicit allocator），要求应用显式地释放任何已分配的块
- 隐式分配器（implicit allocator），要求分配器检测一个已分配块何时不再被程序所使用，那么就释放这个块。这个也称为垃圾收集器

##### 9.9.1 malloc和free函数

动态内存分配器，例如malloc，可以通过使用mmap和munmap函数，显式地分配和释放堆内存，或者还可以使用sbrk函数

```c
#include<unistd.h>
void *sbrk(intptr_t incr);
返回：若成功则为旧的brk指针，若出错则为-1
```

sbrk函数通过将内核的brk指针增加incr来扩展和收缩堆

##### 9.9.2 为什么要使用动态内存分配

程序使用动态内存分配的最重要的原因是经常直到程序实际运行时，才知道某些数据结构的大小

##### 9.9.3 分配器的要求和目标

显式分配器必须在一些相当严格的约束条件下工作

- 处理任意请求序列
- 立即响应请求
- 只使用堆
- 对齐块（对齐要求）
- 不修改已分配的块

##### 9.9.4 碎片

**造成堆利用率很低的主要原因是一种称为碎片（fragmentation）的现象，明明还有内存，但是不满足分配请求的时候，就会出现这种现象**

内部碎片是在一个已分配块比有效载荷大时发生的。

- 在任意时刻，内部碎片的数量只取决于以前请求的模式和分配器的实现方式

**外部碎片是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的**

##### 9.9.6 隐式空闲链表

一个块是由一个字的头部、有效负荷，以及可能的一些额外的填充组成的。

头部编码了这个块的大小（包括头部和所有的填充），以及这个块是已分配的还是空闲的

隐式空闲链表的优点是简单，缺点是任何操作的开销都是线性的

**很重要的一点就是意识到系统对齐要求和分配器堆块格式的选择会对分配器上的最小块大小有强制的要求**

##### 9.9.8 分割空闲块

一旦分配器找到一个匹配的空闲块，它就必须另一个策略决定，那就是分配这个空闲块中多少空间。

如果匹配的不太好，那么分配器通常会选择将这个空闲块分割为两部分

- 第一部分变成分配块，而剩下的变成一个新的空闲块

##### 9.9.9 获取额外的堆内存

如果不能为请求块找到合适的空闲块，那么会发生什么？

首先第一个选择是通过合并那些在内存中物理上相邻的空闲块来创建一些更大的空闲块。

如果还是不行，那么分配器就会通过调用sbrk函数，向内核请求额外的堆内存。

- 分配器将额外的内存转化成一个大的空闲块，将这个块插入到空闲链表中，然后将被请求的块放置在这个新的空闲块中

##### 9.9.10 合并空闲块

当分配器释放一个已分配块时，可能有其他空闲块与这个新释放的空闲块相邻。这些领接的空闲块会引起一种现象，叫做假碎片（fault fragmentation）

- 为了解决假碎片的问题，任何实际的分配器都必须合并相邻的空闲块，这个过程称为合并（coalescing）
  - 可以选择立即合并，也可以推迟合并。
  - 快速的分配器通常都是推迟合并

##### 9.9.11 带边界标记的合并

Knuth提出了一种聪明而通用的技术，叫做边界标记（boundary tag），允许在常数时间内进行对前面块的合并。

**在每个块的结尾处添加一个脚部（footer，边界标记），其中脚部就是头部的一个副本。**

- 如果每个块包括这样一个脚部，那么分配器就可以通过检查它的脚部，判断前面一个块的起始位置和状态，这个脚部总是在距当前块开始位置一个字的距离。

有一种边界标记的优化方法，能够使得在已分配块中不再需要脚部。

- 当我们试图在内存中合并当前块以及前面的块和后面的块时，只有在前面的块是空闲时，才会需要用到它的脚部。
- 如果我们把前面块的已分配/空闲位存放在当前块中多出来的低位中，那么已分配的块就不需要脚部了，这样就可以将这个多出来的空间用作有效载荷了。**空闲块仍然需要脚部**

**书597页，实现一个简单的分配器**

##### 9.9.13 显式空闲链表

使用双向链表而不是隐式空闲链表，使首次适配的分配时间从块总数的线性时间减少到了空闲块数量多线性时间。

- 释放一个块的时间可能是线性的，也可能是个常数，这取决于我们所选择的空闲链表中块的排序策略

一种方法是用后进先出（LIFO）的顺序维护链表，将新释放的块放置在链表的开始处。

另一种方法是按照地址顺序来维护链表，其中链表中每个块的地址都小于它后继的地址。在这种情况下，释放一个块需要线性时间的搜索来定位合适的前驱。平衡点在于，按照地址排序的首次适配比LIFO排序的首次适配有更高的内存利用率，接近最佳适配的利用率

##### 9.9.14 分离的空闲链表

一种流行的减少分配时间的方法，通常称为分离存储（segregated storage），维护多个空闲链表，其中每个链表中的块有大致相等的大小

**1.简单分离存储**

- 每个大小类的空闲链表包含大小相等的块，每个块的大小就是这个大小类中最大元素的大小
- 例如，如果某个大小类定义为{17~32}，那么这个类的空闲链表全由大小为32的块组成

优点：分配和释放块都是很快的常数时间操作。而且，每个片中都是大小相等的块，不分割，不合并，这意味着每个块只有很少的内存开销。

缺点：简单分离存储很容易造成内部和外部碎片

**2.分离适配**

分配器维护着一个空闲链表的数组。

每个空闲链表是和一个大小类相关联的，并且被组织成某种类型的显式或隐式链表

#### 9.10 垃圾回收

未能释放已分配的块是一种常见的编程错误

垃圾收集器（garbage collector）是一种动态内存分配器，它自动释放程序不再需要的已分配块。

##### 9.10.1 垃圾收集器的基本知识

垃圾收集器将内存视为一张有向可达图（reachability graph），该图的节点被分成一组根节点（root node）和一组堆节点（heap node）

**当存在一条从任意根节点出发并到达p的有向路径时，我们说节点p是可达的**

- 不可达节点对应于垃圾，是不能被应用再次使用的

##### 9.10.2 Mark&Sweep垃圾收集器

**标记阶段标记出根节点的所有可达的和已分配的后继，而后面的清除阶段释放每个未被标记的已分配块。**块头部中空闲的低位中的一位通常用来表示这个块是否被标记了

mark函数

```c
void mark(ptr p){
  if((b = isPtr(p)) == NULL)
    return;
  if(blockMarked(b))
    return;
  markBlock(b);
  len = length(b);
  for(i = 0; i < len; i++)
    mark(b[i]);
  return;
}
```

sweep函数

```c
void sweep(ptr b, ptr end){
  while(b < end){
    if(blockMarked(b))
      unmarkBlock(b);
    else if(blockAllocated(b))
      free(b);
    b = nextBlock(b);
  }
  return;
}
```

##### 9.10.3 C程序的保守Mark&Sweep

C语言为isPtr函数的实现造成了一些有趣的挑战

- 第一，C不会用任何类型信息来标记内存位置。因此，对isPtr没有一种明显的方式来判断它的输入参数p是不是一个指针
- 第二，即使我们知道p是一个指针，对isPtr也没有明显的方式来判断p是否指向一个已分配块的有效载荷中的某个位置

对第二个问题的解决方法是将已分配块集合维护成一颗平衡二叉树，这棵树保持着这样一个属性

- 左子树中的所有块都放在较小的地址处，而右子树中的所有块都放在较大的地址处

### 第十章 系统级I/O

#### 10.2 文件

文件类型

- 普通文件（regular file）包含任意数据。
- 目录（directory）是包含一组链接（link）的文件，其中每个链接都将一个文件名（filename）映射到一个文件，这个文件可能是另一个目录
- 套接字（socket）是用来与另一个进程进行跨网络通信的文件

#### 10.3 打开和关闭文件

```c
#include<sys/types.h>
#include<sys/stat/h>
#include<fcntl.h>
int open(char *filename, int flags, mode_t mode);
返回：若成功则为新文件描述符，若出错为-1
	O_RDONLY
  O_WRONLY
  O_RDWR
```

例如``fd = Open("foo.txt", O_RDONLY, 0);``

```c
#include<unistd.h>
int close(int fd);
返回：若成功则为0，若出错则为-1
```

#### 10.4 读和写文件

```c
#include<unistd.h>
ssize_t read(int fd, void *buf, size_t n);
// 返回：若成功则为读的字节数，若EOF则为0，若出错为-1
ssize_t write(int fd, const void *buf, size_t n);
// 返回：若成功则为写的字节数，若出错则为-1
```

在某些情况下，read和write传送的字节比应用程序要求的要少。这些不足值（short count）不表示有错误。出现这样的情况的原因有

- 读时遇到EOF。假设读文件的时候，这个文件只有20个字节，但是我们以50字节的片来读取，就会导致下一个read返回的不足值为20，此后的read将通过返回不足值0来发出EOF信号
- 从终端读文本行。read函数将一次传送一个文本行，返回的不足值等于文本行的大小
- 读和写网络套接字（socket）。内部缓冲约束和较长的网络延迟会引起read和write返回不足值

**实际上，除了EOF，当你在读磁盘文件时，将不会遇到不足值，而且在写磁盘文件时，也不会遇到不足值。**

如果想创建健壮的诸如web服务器这样的网络应用，就必须通过反复调用read和write处理不足值，直到所有需要的字节都传送完毕

#### 10.5 用RIO包健壮地读写

RIO（Robust I/O，健壮的I/O）包，它会自动为你处理上文中所述的不足值。

在像网络程序这样容易出现不足值的应用中，RIO包提供了方便、健壮和高效的I/O。RIO提供了两类不同的函数

- 无缓冲的输入输出函数。这些函数直接在内存和文件之间传送数据，没有应用级缓冲。**对二进制数据读写到网络和从网络读写二进制很有效**
- 带缓冲带输入函数。这些函数允许你高效地从文件中读取文本行和二进制数据，这些文件的内容缓存在应用级缓冲区内，类似于printf提供的缓冲区。**带缓冲带RIO输入函数是线程安全的，它在同一个描述符上可以被交替地调用**

 #### 10.6 读取文件元数据

```c
#include<unistd.h>
#include<sys/stat.h>
int stat(const char *filename, struct stat *buf);
int fstat(int fd, struct stat *buf);
返回：若成功则为0，若出错则为-1
```

#### 10.7 读取目录内容

```c
#include<sys/types.h>
#include<dirent.h>
DIR *opendir(const char *name);
返回：若成功，则为处理的指针；若出错，则为NULL
```

```c
#include<dirent.h>
struct dirent *readdir(DIR *dirp);
返回：若成功，则为指向下一个目录项的指针；若没有更多的目录项或出错，则为NULL
```

```c
#include<dirent.h>
int closedir(DIR *dirp);
返回：成功为0；错误为-1
```

#### 10.8 共享文件

内核用三个相关的数据结构来表示打开的文件

- 描述符表（descriptor table）。每个进程都有它独立的描述符表，它的表项是由进程打开的文件描述符来索引的。每个打开的描述符表项指向文件表中的一个表项
- 文件表（file table）。打开文件的集合是由一张文件表来表示的，所有的进程共享这张表。每个文件表的表项组成（针对我们的目的）包括当前的文件位置、引用计数（reference count）（即当前指向该表项的描述符表项数），以及一个指向v-node表中对应表项的指针。**关闭一个描述符会减少相应的文件表表项中的引用计数。内核不会删除这个文件表表项，直到它的引用计数为零**
- v-node表（v-node table）。同文件表一样，所有的进程共享这张v-node表。**每个表项包含stat结构中的大多数信息，包括st_mode和st_size成员**

#### 10.9 I/O重定向

```c
#include<unistd.h>
int dup2(int oldfd, int newfd);
返回：若成功则为非负的描述符，若出错则为-1
```

dup2函数复制描述符表表项oldfd到描述符表表项newfd，覆盖描述符表表项newfd以前的内容。**如果newfd已经打开了，dup2会在复制oldfd之前关闭newfd**

#### 10.11 综合：我该使用哪些I/O函数？

使用函数的基本指导原则

- 只要有可能就使用标准I/O。对磁盘和终端设备I/O来说，标准I/O函数是首选方法。大多数C程序员在其整个职业生涯中只使用标准I/O，从不受较低级的Unix I/O函数的困扰
- 不要使用scanf或rio_readlineb来读二进制文件。这些是用来读文本文件的，因为二进制文件散步很多的0xa字节，但是这些跟终止文本行无关
- 对网络套接字的I/O使用RIO函数。

标准I/O流，从某种意义上而言是全双工的，因为程序能够在同一个流上执行输入和输出。**然而，对流的限制和对套接字的限制，有时候会互相冲突，而又极少有文档描述这些现象**

- 限制一：跟在输出函数之后的输入函数。**如果中间没有插入对fflush、fseek、fsetpos或者rewind的调用，一个输入函数不能跟随在一个输出函数之后。**fflush函数清空与流相关的缓冲区。后三个函数使用Unix I/O lseek函数来重置当前的文件位置

- 限制二：跟在输入函数之后的输出函数。如果中间没有插入对fseek、fsetpos。**唯一的方法，对同一个打开的套接字描述符打开两个流，一个用来读，一个用来写**

  - ```c
    FILE *fpin, *fpout;
    fpin = fdopen(sockfd, "r");
    fpout = fdopen(sockfd, "w");
    ```

  - 但还是有些问题，还得在两个流上调用fclose，这样才能释放与每个流相关联的内存资源，避免泄露。``fclose(fpin);  fclose(fpout);``

  - **这些操作中的每一个都试图关闭同一个底层的套接字描述符，所以有可能第二个close就会失败，如果在一个线程化的程序中关闭一个已经关闭了的描述符是会出现问题的**

**建议在网络套接字上不要使用标准I/O函数来进行输入和输出，而要使用健壮的RIO函数**

- 如果需要格式化的输出，使用sprintf函数在内存中格式化一个字符串，然后用rio_writen把它发到套接口
- 如果需要格式化输入，使用rio_readlineb来读一个完整的文本行，然后用sscanf从文本行提取不同的字段

### 第十一章 网络编程

#### 11.1 客户端-服务器编程模型

客户端—服务器模型中的基本操作是事务（transaction）

- 当一个客户端需要服务时，它向服务器发送一个请求，发起一个事物
- 服务器收到请求后，解释它，并以适当的方式操作它的资源
- 服务器给客户端发送一个响应，并等待下一个请求
- 客户端收到响应并处理它

**客户端和服务器是进程，而不是常提到的机器或者主机**

客户端-服务器事务不是数据库事务，没有数据库事务的任何特性，例如原子性。在我们的上下文中，事务仅仅是客户端和服务器执行的一系列步骤

#### 11.2 网络

客户端和服务器通常运行在不同的主机上，并且通过计算机网络的硬件和软件资源来通信

对主机而言，网络是一种I/O设备，是数据源和数据接收方

一个插到I/O总线扩展槽的适配器提供了到网络的物理接口。从网络上接收到的数据从适配器经过I/O和内存总线复制到内存，通常是通过DMA传送

#### 11.3 全球IP因特网

因特网的客户端和服务器混合使用套接字接口函数和Unix I/O函数来进行通信。**通常将套接字函数实现为系统调用，这些系统调用会陷入内核，并调用各种内核模式的TCP/IP函数**

##### 11.3.1 IP地址

IP地址是一个32位无符号整数

因特网主机有不同的主机字节顺序，TCP/IP为任意整数数据项定义了统一的网络字节顺序（network byte order）（大端字节顺序）

例如IP地址，它放在包头中跨过网络被携带。**在IP地址结构中存放的地址总是以（大端法）网络字节顺序存放的，即使主机字节顺序（host byte order）是小端法**

Unix提供了下面这样的函数在网络和主机字节顺序间实现转换

```c
#include<arpa/inet.h>
uint32_t htol(uint32_t hostlong);
uint16_t htons(uint16_t hostshort);
返回：按照网络字节顺序的值

uint32_t ntohl(uint32_t netlong);
uint16_t ntohs(uint16_t netshort);
返回：按照主机字节顺序的值
```

htonl函数将32位整数由主机字节顺序转换为网络字节顺序。

ntohl函数将32位整数从网络字节顺序转换为主机字节

应用程序使用inet_pton和inet_ntop函数来实现IP地址和点分十进制串之间的转换

```c
#include<arpa/inet.h>
int inet_pton(AF_INET, const char *src, void *dst);
返回：若成功则为1，若src为非法点分十进制地址则为0，若出错则为-1

const char *inet_ntop(AF_INET, const void *src, char *dst, socklen_t size);
返回：若成功则指向点分十进制字符串的指针，若出错则为NULL
```

在这些函数名中，“n”代表网络，“p”代表表示

#### 11.4 套接字接口

套接字接口（socket interface）是一组函数，它们和Unix I/O函数结合起来，用以创建网络应用。

**书上652页有个图，挺详细的，socket整个流程**

##### 11.4.1 套接字地址结构

从Linux内核的角度来看，一个套接字就是通信的一个端点

sin_family成员是AF_INET，sin_port成员是一个16位的端口号，sin_addr成员是一个32位的IP地址。**IP地址和端口号总是以网络字节顺序（大端）存放的**

```c
// IP socket address structure
struct sockaddr_in{
  uint16_t sin_family; // Protocol family (always AF_INET)
  uint16_t sin_port; // Port number in network by order
  struct in_addr sin_addr; // IP address in network byte order
  unsigned char sin_zero[8]; // Pad to sizeof(struct sockaddr)
};

// Generic socket addresss structure (for connect, bind, and accept)
struct sockaddr{
  uint16_t sa_family; // Protocol family
  char sa_data[14]; // Address data
};
```

**_in后缀意味着什么？**

- _in后缀是互联网络（internet）的缩写，而不是输入（input）的缩写

connect、bind和accept函数要求一个指向与协议相关的套接字地址结构的指针

定义套接字函数要求一个指向通用sockaddr结构的指针，然后要求应用程序将与协议特定的结构的指针强制转换成这个通用结构。

```c
typedef struct sockaddr SA;
```

无论何时需要将sockaddr_in结构强制转换成通用sockaddr结构时，我们都使用这个类型

##### 11.4.2 socket函数

客户端和服务器使用socket函数来创建一个套接字描述符（socket descriptor）

```c
#include<sys/types.h>
#include<sys/socket.h>
int socket(int domain, int type, int protocol);
返回：若成功则为非负描述符，若出错则为-1
```

```c
clientfd = Socket(AF_INET, SOCK_STREAM, 0);
```

- AF_INET表示正在使用32位IP地址
- SOCK_STREAM表示这个套接字是连接的一个端点
- 最好的方法是用getaddrinfo函数来自动生成这些参数，这样代码就与协议无关了

##### 11.4.3 connect函数

客户端通过调用connect函数来建立和服务器的连接

```c
#include<sys/socket.h>
int connect(int clientfd, const struct sockaddr *addr, socklen_t addrlen);
返回：若成功则0，若出错则-1
```

connect函数试图与套接字地址为addr的服务器建立一个因特网连接，其中addrlen是```sizeof(sockaddr_in)``。

- connect函数会阻塞，一直到连接成功建立或者发生错误
- 如果成功，clientfd就可以开始读写了。得到的连接是由套接字对``(x:y, addr.sin_addr:addr.sin_port)``
  - x表示客户端的IP地址，y表示临时端口，它唯一地确定了客户端主机上的客户端进程

**对于socket，最好的方法是用getaddrinfo来为connect提供参数**

##### 11.4.4 bind函数

剩下的套接字函数——bind、listen和accept，服务器用它们来和客户端建立连接

```c
#include<sys/socket.h>
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
返回：若成功则为0，若出错则为-1
```

bind函数告诉内核将addr中的服务器套接字地址和套接字描述符sockfd联系起来

对于socket和connect，最好的方法是用getaddrinfo来为bind提供参数

##### 11.4.5 listen函数

客户端是发起连接请求的主动实体。**服务器是等待来自客户端的连接请求的被动实体**

默认情况下，内核会认为socket函数创建的描述符对应于主动套接字（active socket），它存在于一个连接的客户端

```c
#include<sys/socket.h>
int listen(int sockfd, int backlog);
返回：若成功则为0，若出错则为-1
```

**listen函数将sockfd从一个主动套接字转化为一个监听套接字（listening socket）**，该套接字可以接受来自客户端的连接请求。

backlog参数暗示了内核在开始拒绝连接请求之前，队列中要排队的未完成的连接请求的数量。**通常会设置为一个较大的值，例如1024**

##### 11.4.6 accept函数

服务器通过调用accept函数来等待来自客户端的连接请求

```c
#include<sys/socket.h>
int accept(int listenfd, struct sockaddr *addr, int *addrlen);
返回：若成功则为非负连接描述符，若出错则为-1
```

**accept函数等待来自客户端的连接请求到达侦听描述符listenfd，然后在addr中填写客户端的套接字地址，并返回一个已连接描述符（connected descriptor），这个描述符可被用来利用Unix I/O函数与客户端通信**

监听描述符是作为客户端连接请求的一个端点，它通常被创建一次，并存在于服务器的整个生命周期。

已连接描述符是客户端喝服务器之间已经建立起来了的连接的一个端点。服务器每次接受连接请求时都会创建一次，它只存在于服务器为一个客户端服务的过程中

##### 11.4.7 主机和服务的转换

Linux提供了一些强大的函数（称为getaddrinfo和getnameinfo）实现二进制套接字地址结构和主机名、主机地址、服务名和端口号的字符串表示之间的相互转换。

**1.getaddrinfo函数**

getaddrinfo函数将主机名、主机地址、服务名和端口号的字符串表示转化成套接字地址结构。**它是已启用的``gethostbyname``和``getservbyname``函数的新的替代品，这个函数是可重入的，适用于任何协议**

```c
#include<sys/types.h>
#Include<sys/socket.h>
#include<netdb.h>
int getaddrinfo(const chr *host, const char *service,
               const struct addrinfo *hints,
               struct addrinfo **result);
返回：如果成功则为0，如果错误则为非零的错误代码
void freeaddrinfo(struct addrinfo *result);
返回：无
const char *gai_strerror(int errcode);
返回：错误消息
```

在客户端调用了getaddrinfo之后，会遍历这个列表，依次尝试每个套接字地址，直到调用socket和connect成功，建立起连接。

服务器会尝试遍历列表中的每个套接字地址，直到调用socket和bind成功，描述符会绑定到一个合法的套接字地址。

**为了避免内存泄露，应用程序在最后调用freeaddrinfo，释放该链表**

如果getaddrinfo返回非零的错误代码，应用程序可以调用gai_strerror，将该代码转换成消息字符串

**2.getnameinfo函数**

getnameinfo函数是将一个套接字地址结构转换成相应的主机和服务名字符串

它是已弃用的``gethostbyaddr``和``getservbyport``函数的新的替代品，是可重入和与协议无关的

```c
#include<sys/socket.h>
#include<netdb.h>
int getnameinfo(const struct sockaddr *sa, socklen_t salen,
               char *host, size_t hostlen,
               char *service, size_t servlen, int flags);
返回：如果成功则为0，如果错误则为非零的错误代码
```

##### 11.4.8 套接字接口的辅助函数

初学时，getnameinfo函数和套接字接口看上去有点可怕。可以用高级的辅助函数包装一下，会方便很多，称为open_clientfd和open_listenfd，客户端和服务器互相通信时可以使用这些函数

**1.open_clientfd函数**

客户端调用open_clientfd建立与服务器的连接

```c
#include "csapp.h"
int open_clientfd(char *hostname, char *port);
返回：若成功则为描述符，若出错则为-1
```

实际操作，调用getaddrinfo，它返回addrinfo结构的列表，每个结构指向一个套接字地址结构，可用于建立与服务器的连接，该服务器运行在hostname上并监听port端口。

然后遍历该列表，依次尝试列表中的每个条目，直到调用socket和connect成功。如果connect失败，再尝试下一个条目之前，要小心地关闭套接字描述符。如果connect成功，我们会释放列表内存，并把套接字描述符返回给客户端，客户端可以立即开始用Unix I/O与服务器通信了

**注意，所有的代码都与任何版本的IP无关。socket和connect的参数都是用getaddrinfo自动产生的，这使得我们的代码干净可移植**

**2.open_listenfd函数**

服务器创建一个监听描述符，准备好接收连接请求。

```c
#include "csapp.h"
int open_listenfd(char *port);
返回：若成功则为描述符，若出错则为-1
```

具体过程类似于open_clientfd，调用getaddrinfo，然后遍历结果列表，直到调用socket和bind成功。

使用setsockopt函数来配置服务器，使得服务器能够被终止、重启和立即开始接收连接请求。一个重启的服务器默认将在大约30秒内拒绝客户端的连接请求，这严重地阻碍了调试

最后调用listen函数，将listenfd转换为一个监听描述符，并返回给调用者。如果listen失败，我们要小心地避免内存泄露，在返回前关闭描述符

#### 11.5 Web服务器

##### 11.5.3 HTTP事务

**1.HTTP请求**

一个请求行，一个或更多个请求报头，再跟随一个空的文本行来终止报头列表

请求行的形式：method URI version

请求报头的格式：header-name：header-data

**2.HTTP响应**

一个响应行，后面跟随着零个或更多的响应报头，再跟随一个终止报头的空行，再跟随一个响应主体

响应行格式：version status-code status- message

##### 11.5.4 服务动态内容

CGI（Common Gateway Interface，通用网关接口）

**1.客户端如何将程序参数传递给服务器**

GET请求的参数在URI中传递。“？”字符分隔了文件名和参数，而每个参数都用一个“&”字符分隔开。参数中不允许有空格，而必须用字符串“%20“来表示

**2.服务器如何将参数传递给子进程**

当服务器接收一个请求：``GET /cgi-bin/adder?15000&213 HTTP/1.1``

调用fork来创建一个子进程，并调用execve在子进程的上下文中执行``/cgi-bin/adder``程序

像adder这样的程序，常常被称为CGI程序，因为它们遵守CGI标准的规则。**许多CGI程序是用Perl脚本编写的，所以CGI程序也常被称为CGI脚本**

在调用execve之前，子进程将CGI环境变量QUERY_STRING设置为“15000&213”，adder程序在运行时可以用Linux getev函数来引用它。

**3.服务器如何将其他信息传递给子进程**

CGI定义了大量的其他环境变量，一个CGI程序在它运行时可以设置执行环境变量

```sh
QUERY_STRING # 程序参数
SERVER_PORT # 父进程侦听的端口
REQUEST_METHOD # GET 或 POST
REMOTE_HOST # 客户端的域名
REMOTE_ADDR # 客户端的点分十进制IP地址
CONTENT_TYPE # 只对POST而言：请求体的MIME类型
CONTENT_LENGTH # 只对POST而言：请求体的字节大小
```

**4.子进程将它的输出发送到哪里**

在子进程加载并运行CGI程序之前，它使用Linux dup2函数将标准输出重定向到和客户端相关联的已连接描述符。

**因此，任何CGI程序写到标准输出到东西都会直接到达客户端**

注意，因为父进程不知道子进程生成的内容的类型或大小，所以子进程就要负责生成Content-type和Content-length响应报头，以及终止报头的空行

**对于POST请求，子进程也需要重定向标准输入到已连接描述符。然后CGI程序会从标准输入中读取请求主体中的参数**

### 第十二章 并发编程

#### 12.1 基于进程的并发编程

一个构造并发服务器的自然方法就是，在父进程中接受客户端连接请求，然后创建一个新的子进程来为每个新客户端提供服务

##### 12.1.1 基于进程的并发服务器

关于服务器的重要内容

- 首先，通常服务器会运行很长的时间，所以我们必须要包括一个SIGCHLD处理程序，来回收僵死（zombie）子进程的资源。因为当SIGCHLD处理程序执行时，SIGCHLD信号是阻塞的，而Linux信号是不排队的，所以SIGCHLD处理程序必须准备好回收多个僵死子进程的资源
- 其次，父子进程必须关闭它们各自的connfd副本。避免内存泄露
- 最后，因为套接字的文件表表项中的引用计数，直到父子进程的connfd都关闭了，到客户端的连接才会终止

##### 12.1.2 进程的优劣

进程共享文件表，但是不共享用户地址空间。

进程有独立的地址空间既是优点也是缺点。这样一来，一个进程不可能不小心覆盖另一个进程的虚拟内存，这就消除了许多令人迷惑的错误

另一方面，独立的地址空间使得进程共享状态信息变得更加困难。为了共享信息，它们必须使用显式的IPC（进程间通信）机制。

进程往往比较慢，因为进程控制和IPC的开销很高

#### 12.2 基于I/O多路复用的并发编程

基本的思路是使用select函数，要求内核挂起进程，只有在一个或多个I/O事件发生后，才将控制返回给应用程序

select函数处理类型为fd_set的集合，也叫做描述符集合

只能对描述符集合做三件事

- 分配它们
- 将一个此种类型的变量赋值给另一个变量
- 用FD_ZERO、FD_SET、FD_CLR和FD_ISSET宏来修改和检查它们

select函数有两个输入：一个称为读集合的描述符集合（fdset）和该读集合的基数（n）

**select函数会一直阻塞、直到读集合中至少有一个描述符准备好可以读。**

**select副作用**

- 它修改参数fdset指向的fd_set，指明读集合的一个子集，称为准备好集合（ready set），这个集合是由读集合中准备好可以读了的描述符组成
- 所以，必须每次调用select时都更新读集合

##### 12.2.1 基于I/O多路复用的并发事件驱动服务器

一般的思路是将逻辑流模拟化为状态机

**一个状态机（state machine）就是一组状态、输入事件和转移**

- 其中转移是将状态和输入事件映射到状态

- **每个转移是将一个（输入状态，输入事件）对应到一个输出状态**
- 自循环是同一输入和输出状态之间的转移

**每个输入事件都会引发一个从当前状态到下一状态的转移**

##### 12.2.2 I/O多路复用技术的优劣

事件驱动设计的优点：它比基于进程的设计给了程序员更多的对程序行为的控制

一个基于I/O多路复用的事件驱动服务器是运行在单一进程上下文中的，因此每个逻辑流都能访问该进程的全部地址空间

缺点是不能充分利用多核处理器

#### 12.3 基于线程的并发编程

**线程是运行在进程上下文中的逻辑流**

程序都是由每个进程中一个线程组成的。现代系统允许一个进程里同时运行多个线程的程序。

**线程由内核自动调度。每个线程都有它自己的线程上下文（thread context）**

- 包括一个唯一的整数线程ID（Thread ID，TID）、栈、栈指针、程序计数器、通用目的寄存器和条件码
- 所有的运行在一个进程里的线程共享该进程的整个虚拟地址空间

##### 12.3.1 线程执行模型

每个进程开始生命周期时都是单一线程，这个线程称为主线程（main thread）

**在某一时刻，主线程创建一个对等线程（peer thread），从这个时间点开始，两个线程就并发地运行**

- 最后因为主线程执行一个慢速系统调用，例如read或者sleep，或者因为被系统的间隔计时器中断。控制就会通过上下文切换传递到对等线程
- 对等线程会执行一段时间，然后控制传递回主线程

进程相关的线程组成一个对等（线程）池，独立于其他线程创建的线程。

主线程和其他线程的区别仅在于它总是进程中第一个运行的线程。

**对等（线程）池概念的主要影响是，一个线程可以杀死它的任何对等线程，或者等待它的任意对等线程终止。每个对等线程都能读写相同的共享数据**

##### 12.3.2 Posix线程

Posix线程（Pthreads）是在C程序中处理线程的一个标准接口。

Pthreads定义了大约60个函数，允许程序创建、杀死和回收线程，与对等线程安全地共享数据

##### 12.3.3 创建线程

线程通过调用pthread_create函数来创建其他线程

```c
#include<pthread.h>
typedef void *(func)(void *);
int pthread_create(pthread_t *tid, pthread_attr_t *attr,
                  func *f, void *arg);
返回：若成功则0，出错则为非零
```

##### 12.3.4 终止线程

- 当顶层的线程例程返回时，线程会隐式地终止
- 通过调用pthread_exit函数，线程会显示地终止。如果主线程调用pthread_exit，它会等待所有其他对等线程终止，然后再终止主线程和整个线程，返回值为thread_return

```c
#include<pthread.h>
void pthread_exit(void *thread_return);
从不返回
```

- 某个对等线程调用Linux的exit函数，该函数终止进程以及所有与该进程相关的线程
- 另一个对等线程通过以当前线程ID作为参数调用pthread_cancel函数来终止当前线程

```c
#include<pthread.h>
int pthread_cancel(pthread_t tid);
返回：若成功返回0，出错返回非零
```

##### 12.3.5 回收已终止线程的资源

线程通过调用pthread_join函数等待其他线程终止

```c
#include<pthread.h>
int pthread_join(pthread_t tid, void **thread_return);
返回：若成功返回0，出错返回非零
```

和Linux的wait函数不同，pthread_join函数只能等待一个指定的线程终止，没有办法让pthread_wait等待任意一个线程终止

##### 12.3.6 分离线程

在任何一个时间点上，线程是可结合的（joinable）或者是分离的（detached）

一个可结合的线程能够被其他线程回收和杀死。在被其他线程回收之前，它的内存资源（例如栈）是不释放的。

**一个分离的线程是不能被其他线程回收或杀死的，它的内存资源在它终止时由系统自动释放**

默认情况下，线程被创建成可结合的。为了避免内存泄漏，每个可结合线程都应该要么被其他线程显式地收回，要么通过调用pthread_detach函数被分离

```c
#include<pthread.h>
int pthread_detach(pthread_t tid);
返回：成功为0，出错为非零
```

##### 12.3.7 初始化线程

```c
#include<pthread.h>
pthread_once_t once_control = PTHREAD_ONCE_INIT:
int pthread_once(pthread_once_t *once_control,
                void (*init_routine)(void));
返回：0
```

#### 12.4 多线程程序中的共享变量

##### 12.4.1 线程内存模型

一组并发线程运行在一个进程的上下文中。每个线程都有它自己独立的线程上下文，包括线程ID、栈、栈指针、程序计数器、条件码和通用目的寄存器值

每个线程和其他线程一起共享进程上下文的剩余部分。包括整个用户虚拟地址空间，它是由只读文本（代码）、读/写数据、堆以及所有的共享库代码和数据区域组成的

#### 12.5 用信号量同步线程

##### 12.5.2 信号量

信号量s是具有非负整数值的全局变量，只能由两种特殊的操作来处理，这两种特殊的操作称为P和V

- P（s）：如果s是非零的，那么P将s减1，并且立即返回。如果s为零，那么就挂起这个线程
- V（s）：V操作将s加1。如果有任何线程阻塞在P操作等待s变成非零，那么V操作会重启这些线程中的一个，然后该线程将s减1，完成它的P操作

```c
#include<semaphore.h>
int sem_init(sem_t *sem, 0, unsigned int value);
int sem_wait(sem_t *s); // P(s)
int sem_post(sem_t *s); // V(s)
```

##### 12.5.3 使用信号量来实现互斥

以提供互斥为目的的二元信号量常常也称为互斥锁（mutex）

对一个互斥锁加了锁但是还没有解锁的线程称为占用这个互斥锁

##### 12.5.4 利用信号量来调度共享资源

**1.生产者-消费者问题**

生产者产生项目并把它们插入到一个有限的缓冲区中，消费者从缓冲区中取出这些项目，然后消费它们

**2.读者-写者问题**

一组并发的线程要访问一个共享对象，例如一个主存中的数据结构，或者一个磁盘上的数据库。有些线程只读对象，而其他的线程只修改对象。

修改对象的线程叫做写者，只读对象的线程叫做读者。**写者必须拥有对对象的独占的访问，而读者可以和无限多个其他的读者共享对象**

#### 12.7 其他并发问题

##### 12.7.1 线程安全

一个函数被称为线程安全的（thread-safe），当且仅当被多个并发线程反复地调用时，它会一直产生正确的结果。

四个线程不安全函数类

- 不保护共享变量的函数
- 保持跨越多个调用的状态的函数
- 返回指向静态变量的指针的函数
- 调用线程不安全的函数的函数

##### 12.7.2 可重入性

有一类重要的线程安全函数，叫做可重入函数（reentrant function），其特点在于它们具有这样一种属性：**当它们被线程调用时，不会引用任何共享数据**

##### 12.7.4 竞争

当一个程序的正确性依赖于一个线程要在另一个线程到达y点之前到达它的控制流中的x点时，就会发生竞争（race）

多线程的程序必须对任何可行的轨迹线都正确工作

##### 12.7.5 死锁

一组线程被阻塞了，等待一个永远也不会为真的条件

关于死锁的重要知识

- 程序员使用P和V操作顺序不当，以至于两个信号量的禁止区域重叠
- 重叠的禁止区域引起了一组称为死锁区域（deadlock region）的状态
- 死锁是一个相当困难的问题，因为它不总是可预测的


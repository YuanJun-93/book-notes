### 第一章 计算机系统漫游

#### 1.1 信息就是位+上下文

hello.c程序是以字节序列的方式存在文件中的

系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。

区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文

- 在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令

#### 1.2 程序被其他程序翻译成不同的格式

在Unix系统上，从源文件到目标文件的转化是由编译器驱动程序完成的

- ``gcc -o hello hello.c``
- GCC编译器驱动程序读取源程序文件hello.c，并翻译成一个可执行目标文件hello

翻译过程分成四个阶段

- 预处理阶段。根据以字符#开头的命令，修改原始的C程序
- 编译阶段。编译器（cc1）将文本文件hello.i翻译成文本文件hello.s。它包含一个汇编语言程序
- 汇编阶段。 汇编器将hello.s翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序的格式，并将结果保存在目标文件hello.o中（二进制文件）
- 链接阶段。如果调用了其他函数，需要将这个函数的文件合并到hello.o程序中

#### 1.4 处理器读并解释储存在内存中的指令

#####  1.4.1 系统的硬件组成

- 总线。它携带信息字节并负责在各个部件间传递，通常总线被设计成传送定长的字节块，也就是字（word）
- I/O设备。I/O（输入/输出）设备是系统与外部世界的联系通道，每个I/O设备都通过一个控制器或适配器与I/O总线相连
  - 控制器是I/O设备本身或者系统的主印制电路板（主板）上的芯片组
  - 适配器是一块插在主板插槽上的卡
  - 它们功能都是在I/O总线和I/O设备之间传递信息
- 主存。临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据
  - 从物理上来说，主存是由一组动态随机存取存储器（DRAM）芯片组成
  - 从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），从0开始
- 处理器。解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC），在任何时刻，PC都指向主存中的某条机器语言指令（即含有该条指令的地址）
  - 加载：从主存复制一个字节或者一个字到寄存器，覆盖寄存器原来内容
  - 存储：从寄存器复制一个字节或者一个字到主存的某个位置，覆盖这个位置原来的内容
  - 操作：把两个寄存器内容复制到ALU，ALU对这两个字做算术运算，并将结果放到一个寄存器中，覆盖该寄存器原来的内容
  - 跳转：从指令本身中抽取一个字，并将这个字复制到程序计数器（PC）中，覆盖原本PC中的值

#### 1.5 高速缓存至关重要

L1和L2高速缓存是用一种静态随机访问存储器（SRAM）

在高速缓存里面放经常访问的数据

#### 1.7 操作系统管理硬件

操作系统是应用程序和硬件之间插入的一层软件，**所有应用程序对硬件的操作尝试都必须通过操作系统**

操作系统两个基本功能

- 防止硬件被失控的应用程序滥用
- 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备

文件是对I/O设备抽象的表示

虚拟内存是对主存和硬盘I/O设备的抽象表示

进程是对处理器、主存和I/O设备的抽象表示

##### 1.7.1 进程

进程是操作系统对一个正在运行的程序的一种抽象。

并发运行，是说一个进程的指令和另一个进程的指令是交错执行的（上下文切换）。

操作系统保持跟踪进程运行所需的所有状态信息，也就是上下文

- 比如PC和寄存器文件的当前值，以及主存的内容

从一个进程到了一个进程到转换是由操作系统内核管理的，内核是操作系统代码常驻主存的部分，当应用程序需要操作系统的某些操作时，比如读写文件，**它就执行一条特殊的系统调用（system call）指令，将控制权传递给内核**。然后内核执行被请求的操作并返回应用程序

**内核不是一个独立的进程，它是系统管理全部进程所用代码和数据结构的集合**

##### 1.7.2 线程

一个进程可以由多个称为线程的执行单元组成，**每个线程都运行在进程上下文中，并共享同样的代码和数据**

多线程之间比多进程之间更容易共享数据

线程一般比进程更高效

##### 1.7.3 虚拟内存

虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。

**每个进程看到的内存都是一致的，称为虚拟地址空间**

进程的虚拟地址空间，从最低的地址开始，逐步向上

- 程序代码和数据。直接按照可执行目标文件的内容初始化的，在进程一开始运行时就指定了大小
- 堆。当调用malloc和free这样的C标准库函数时，堆可以动态地扩展和收缩
- 共享库。大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区域
- 栈。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用，每次调用一个函数时，栈就会增长，从一个函数返回时，栈就会收缩
- 内核虚拟空间。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。

基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为磁盘的高速缓存

##### 1.7.4 文件

文件就是字节序列，仅此而已。

每个I/O设备，包括磁盘、键盘、显示器，甚至网络都可以看成是文件。

系统中的所有输入输出都是通过使用一小组称为UnixI/O的系统函数调用读写文件来实现的。

#### 1.9 重要主题

##### 1.9.2 并发和并行

**1.线程级并发**

单处理器中，传统意义上，并发只是模拟出来的，使一台计算机在它正在执行的进程间快速切换来实现的。

多核处理器是将多个CPU（称为“核”）集成到一个集成电路芯片上。

典型多核处理器的组织结构，其中微处理器芯片有4个CPU核，每个核都有自己的L1核L2高速缓存，其中的L1高速缓存分为两个部分——一个保存最近取到的指令，了一个存放数据。**这些核共享更高层次的高速缓存，以及到主存的接口**

超线程，有时称为同时多线程，是一项运行一个CPU执行多个控制流的技术。

- 它涉及CPU某些硬件有多个备份，比如程序计数器和寄存器文件，而其他的硬件部分只有一份，比如执行浮点算术运算的单元
- 常规的处理器需要大约20000个时钟周期做不同线程间转换，而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程，**使得CPU能够更好地利用它的处理资源**

多处理器的使用可以从两方面提高系统性能

- 减少了在执行多个任务时模拟并发的需要
- 可以使应用程序运行得更快

**2.指令级并行**

现代处理器可以同时执行多条指令的属性称为指令级并行

如果处理器可以达到比一个周期一条指令更快的执行速率，就称为超标量处理器，大多数现代处理器都支持超标量操作

**3.单指令、多数据并行**

许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即SIMD并行

### 第二章 信息的表示和处理

无符号编码基于传统的二进制表示法，表示大于或者等于零的数字。

补码编码是表示有符号整数的最常见的方式，有符号整数就是可以为正或者为负的数字

浮点数编码是表示实数的科学记数法的以2为基数的版本

**大量的计算机的安全漏洞都是由于计算机算术运算的微妙细节引发的**

#### 2.1 信息存储

大多数计算机使用8位的块，或者字节（byte），作为最小的可寻址的内存单位，而不是访问内存中单独的位

内存的每个字节都由唯一的数字来标识，称为地址，所有地址的集合称为虚拟地址空间

每个程序对象可以简单地视为一个字节块，而程序本身就是一个字节序列

##### 2.1.2 字数据大小

每台计算机都有一个字长（word size），**字长决定虚拟地址空间的大小**

- 假设字长为w位，虚拟地址的范围0～（2的w次方）-1

**32位字长，限制虚拟地址空间为4GB，64位是16EB**

一般数据格式都是4字节，double和int64是8字节，short2字节，char1字节

小端表示法：最低有效字节在最前面，[67，45，23，01]

大端表示法：最高有效字节在最前面，[01，23，45，67]

**Android和IOS只能使用小端模式**

Unicode（统一字符集），使用32位来表示字符

异或交换值

```c
y = x ^ y;
x = x ^ y;
y = x ^ y;
```

#### 2.2 整数表示

##### 2.2.1 整型数据类型

负数的范围逼整数的范围大1

C和C++都支持有符号和无符号数，Java只支持有符号数

43～108 jump

补码等等一大堆运算跳过了，以后回来看

### 第三章 程序的机器级表示

#### 3.2 程序编码

##### 3.2.1 机器级代码

程序内存包含

- 程序的可执行机器代码
- 操作系统需要的一些信息
- 用来管理过程调用和返回的运行时栈
- 用户分配的内存块

GCC运行编译器，-s产生一个.s的汇编文件，里面都是汇编代码，-c产生.o结尾的目标文件

#### 3.3 数据格式

Intel用术语：字（word）表示16位数据类型，32位称为双字，64位称为四字

浮点数主要有两种形式：单精度（4字节）值，双精度（8字节）值

#### 3.4 访问信息

一个x86-64的中央处理单元（CPU）包含一组16个存储64位值的通用目的寄存器：从%r8到%r15

##### 3.4.2 数据传送指令

MOV

- movb，1
- movw，2
- movl，4
- movq，8字节

Mov指令操作：第一个是原操作数，第二个是目的操作数

##### 3.6.6 用条件传送来实现条件分支

**if else效率低**

```c
long absdiff(long x, long y){
  long result;
  if(x < y)
    result = y - x;
  else
    result = x - y;
  return result;
}
```

模拟汇编代码，基于条件数据传送的代码，使用条件赋值的实现

```C
long cmovdiff(long x, long y){
	long rval = y-x;
  long eval = x-y;
  long ntest = x >= y;
  if(ntest)
    rval = eval
  return rval;
}
```

**基于条件数据传送的代码会比基于条件控制转移的代码性能要好**

##### 3.6.8 switch语句

switch语句可以根据一个整数索引值进行多重分支

- 可以通过使用跳转表（jump table）这种数据结构使得实现更加高效
- 跳转表是一个数组，优点是执行开关语句的时间与开关情况的数量无关
- 当开关情况数量比较多（4个以上），并且值的范围跨度比较小时，就会使用跳转表

#### 3.7 过程

过程的形式多样：函数、方法、子例程、处理函数等等

假设过程调用P调用过程Q，Q执行后返回到P

- 传递控制。在进入过程Q的时候，程序计数器必须被设置为Q的代码的起始地址，然后在返回时，要把程序计数器设置为P中调用Q后面那条指令的地址
- 传递数据。P必须能够向Q提供一个或多个参数，Q必须能够向P返回一个值
- 分配和释放内存。在开始时，Q可能需要为局部变量分配空间，而在返回前，又必须释放这些存储空间

##### 3.7.1 运行时栈

程序用栈来管理它的过程所需要的存储空间，栈和程序寄存器存放着传递控制和数据、分配内存所需要的信息。

- 当P调用Q时，控制和数据信息添加到栈尾
- 当P返回时，这些信息就会被释放掉

当x86-64过程需要的存储空间超出寄存器能够存放的大小时，就会在栈上分配空间

- **这个部分称为过程的栈帧**

##### 3.7.2 转移控制

将控制从函数P转移到函数Q需要简单地把程序计数器（PC）设置为Q的代码的起始位置

- 当从Q返回时，处理器必须记录好它需要继续P当执行的代码位置

##### 3.7.4 栈上的局部存储

有些时候，局部数据必须存放在内存中，常见的情况

- 寄存器不足够存放所有的本地数据
- 对一个局部变量使用地址运算符“&”，因此必须能够为它产生一个地址
- 某些局部变量是数组或结构，因此必须能够通过数组或结构引用被访问到

函数P调用两层Q

```c
long P(long x, long y){
  long u = Q(y);
  long v = Q(x);
  return u + v;
}
```

汇编代码

```c
P:
	pushq %rbp
  pushq %rbx
  subq $8, %rsp
  movq %rdi, %rbp
  movq %rsi, %rdi
  call Q
  movq %rax, %rbx
  movq %rbp, %rdi
  call Q
  addq %rbx, %rax
  addq %8, %rsp
  popq %rbx
  popq %rbp
  ret
```

在第一次调用中，必须保存x的值，第二次调用中，必须保存Q(y)的值

#### 3.8 数组分配和访问

##### 3.8.2 指针运算

单操作数操作符'&'和'*'可以产生指针和间接引用指针

对于一个对象的表达式Expr

- *AExpr表示的是值
- &Expr表示的是指向这个地址的指针
- 表达式Expr与*&Expr是等价的
- 引用数组A[i]等同于表达式*(A+ i )

##### 3.8.4 定长数组

好的编码习惯

```c
#define N 16
typedef int fix_matrix[N][N]
```

#### 3.9 异质的数据结构

##### 3.9.3 数据对齐

许多计算机系统对基本数据类型的合法地址做出来一些限制，要求某种类型对象的地址必须是某个值K（通常是2、4或8）的倍数

- 这种对齐限制简化了形成处理器和内存系统之间接口的硬件设计

假设一个处理器总是从内存取8个字节，则地址必须为8的倍数。

- **如果我们能保证将所有的double类型数据的地址对齐成8的倍数，那么就可以用一个内存操作来读或者写值**
- 否则就可能需要执行两次内存访问，因为对象可能被分放在两个8字节内存块中

**注意：无论数据是否对齐，x86-64硬件都能正确工作**

- 还是建议对齐数据，来提高内存系统的性能
- 对齐原则：任何K字节的基本对象的地址必须是K的倍数

例如

```c
struct S1{
  int i;
  char c;
  int j;
}
```

假设编译器用最小的9字节分配，那么中间就会有1个字节的char，满足不了4个字节的int，所以中间需要补3个字节。**结果整个结构大小就会变成12字节**

假如对齐

```c
struct S2{
  int i;
  int j;
  char c;
}
```

这样子，只要保证结构的起始地址满足4字节对齐要求，我们仍然能保证满足字段i和j的对齐要求

- 但是如果这样声明，``struct S2 d[4]``，还是会有3个字节被浪费掉，没办法

##### 3.10 在机器级程序中将控制与数据结合起来

##### 3.10.1 理解指针

**函数指针**

```c
int (*f)(int*)
```

- 返回值int
- f是函数名
- *f意思是指向f这个函数的指针，也就是函数指针
- (Int*) 表示参数是一个int类型的指针，参数名省略了，没有写出来

- (*f)加括号是防止跟前面的返回值int混淆了

##### 3.10.4 对抗缓冲区溢出攻击

- 栈随机化
  - 地址空间布局随机化（Address-Space Layout Randomization）
  - 每次运行时程序的不同部分，包括程序代码、库代码、栈、全局变量和堆数据，都会被加载到内存的不同区域
  - 这种方法会被暴力破解，在攻击代码前面加很长的nop（no operation），执行这种指令之后，会使程序计数器加1，只要攻击者能够猜到某个地址，然后程序就会执行恶意代码
- 栈破坏检测
  - 在栈帧中任何局部缓冲区与栈状态之间存储一个特殊的金丝雀（canary）值，是在程序每次运行时随机产生的，在恢复寄存器状态之前，程序检测金丝雀值是否被改变，如果被改变了，程序就中止
- 限制可执行代码区域
  - 只有保存编译器产生的代码的那部分内存才是可执行的

### 第四章 处理器体系结构

x86-64有时称为“复杂指令集计算机”（CISC，读作“sisk”）与“精简指令集计算机”（RISC）相对。

##### 4.2.5 存储器和时钟

存储设备都是由同一个时钟控制的，时钟是一个周期性的信号，决定什么时候要把新值加载到设备中

- 时钟寄存器（简称寄存器）存储单个位或字。时钟信号控制寄存器加载输入值
- 随机访问存储器（简称内存）存储多个字，用地址来选择该读或该写哪个字
  - 处理器的虚拟内存系统
  - 寄存器文件

大多数实际系统中，是一个具有双端口的存储器：一个用来读指令，另一个用来读或者写数据

处理器的各个阶段

- 取指（fetch）：取指阶段从内存读取指令字节，地址为程序计数器（PC）的值。
- 译码（decode）：从寄存器文件中读入最多两个操作数，得到值valA和valB。
- 执行（execute）：在执行阶段，算术/逻辑单元（ALU）要么执行指令指明的操作（根据ifun的值），计算内存引用的有效地址，要么增加或减少栈指针。
- 访存（memory）：访存阶段可以将数据写入内存，或者从内存读出数据。
- 写回（write back）：写回阶段最多可以写两个结果到寄存器文件。
- 更新PC（PC update）：将PC设置成下一条指令的地址。

**处理器无限循环，执行这些阶段**

执行流程在书的272页有一个图，SEQ的抽象视图，很直观，描述的就是上面这几个阶段

SEQ的实现包括组合逻辑和两种存储器设备

- 时钟寄存器（程序计数器和条件码寄存器）
- 随机访问存储器（寄存器文件、指令内存和数据内存）

**处理器从来不需要为了完成一条指令的执行而去读由该指令更新了的状态**

**SEQ这种实现方法不能充分利用硬件单元，因为每个单元只在整个时钟周期的一部分时间内才被使用**

#### 4.4 流水线的通用原理

流水线化的一个重要特性就是提高了系统的吞吐量（throughput），也就是单位时间内服务的顾客总数，不过也会轻微的增加延迟（latency），也就是服务一个用户所需要的时间

##### 4.4.1 计算流水线

它是由一些执行计算的逻辑以及一个保存计算结果的寄存器组成的。

时钟信号控制在每个特定的时间间隔加载寄存器。

在现代逻辑设计中，电路延迟以微微秒或皮秒（picosecond，简写成“ps”），也就是10的-12次分秒位单位。

**以每秒千兆条指令（GIPS），也就是每秒十亿条指令，为单位来描述吞吐量**

- 从头到尾执行一条指令所需要的时间称为延迟（latency）

缓慢时钟不会影响流水线的行为，信号传播到流水线寄存器到输入，但是直到时钟上升时才会改变寄存器到状态。

SEQ与SEQ+

- SEQ中，PC计算发生在时钟周期结束的时候，根据当前时钟周期内计算出的信号值来计算PC寄存器的新值
- SEQ+中，创建状态寄存器来保存在一条指令执行过程中计算出来的信号，然后当一个新的时钟周期开始时，这些信号值通过同样的逻辑来计算当前指令的PC

SEQ+的图在书的290页

**数据冒险在书的298页有总结**

##### 4.5.6 异常处理

处理器中很多事情都会导致异常控制流，此时，程序执行的正常流程被破坏掉

**异常可以从内部产生，也可以由外部信号产生**

内部异常

- halt指令
- 有非法指令和功能码组合的指令
- 取指或数据读写试图访问一个非法地址

为了避免异常指令之后的指令更新任何程序员可见的状态，当处于访存或写回阶段中的指令导致异常时，流水线控制逻辑必须禁止更新条件码寄存器或是数据内存。

### 第五章 优化程序性能

编写高效的程序需要做到以下几点

- 第一，我们必须选择一组适当的算法和数据结构
- 第二，我们必须编写出编译器能够有效优化以转换成高效可执行代码的源代码
  - 理解优化编译器的能力和局限性是很重要的

**尽管做了大量的变化，但还是要维护代码一定程度的简洁和可读性**

#### 5.2 表示程序性能

度量标准每元素的周期数（Cycles Per Element，CPE）

#### 5.3 程序示例

使用define定义，然后使用命令行选项，``-O1``进行优化

- 可以显著的提高程序性能——超过两个数量级

#### 5.4 消除循环的低效率

将循环变量条件写外面，不要每次都计算

例如

```c
void combine1(vec_ptr v, data_t *dest){
	long i;
  *dest = IDENT;
  for(i = 0; i < vec_length(v); i++){
    data_t val;
    get_vec_element(v, i, &val);
    *dest = *dest OP val;
  }
}
```

```c
void combine2(vec_ptr v, data_t *dest){
	long i;
	long length = vec_length(v);
  *dest = IDENT;
  for(i = 0; i < length; i++){
    data_t val;
    get_vec_element(v, i, &val);
    *dest = *dest OP val;
  }
}
```

**combine2的效果要比combine1好，仅仅移动计算length的位置，就可以有性能上的提升，如果求长度是一个需要每次遍历的函数，那么这个优化就能起到很大的作用，不需要每次循环都遍历求一次长度**

这个优化是一类常见的优化的一个例子，**称为代码移动（code motion）**

- 优化包括识别要执行多次（例如在循环里）但是计算结果不会改变的计算

#### 5.5 减少过程调用

例如直接取数组下标，每次通过数组下标取指，都会进行一次边界检测，实际上也会影响性能，**影响并不是很大**

```c
data_t *get_vec_start(vec_ptr v){
  return v->data;
}
void combine3(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  data_t *data = get_vec_start(v);
  *dest = IDENT;
  for(i = 0; i < length(); i++){
    *dest = *dest OP data[i];
  }
}
```

事实上，整数求和的性能还略有下降

#### 5.6 消除不必要的内存引用

combine3中的dest是一个指针，所以每次累加求和的时候，这个指针都要加8，累积变量的数值都要从内存读出然后再写入到内存。这样的读写很浪费

```c
void combine3(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  data_t *data = get_vec_start(v);
  data_t acc = IDENT;
  for(i = 0; i < length(); i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

#### 5.7 理解现代处理器

##### 5.7.1 整体操作

超标量：意思是处理器可以在每个时钟周期执行多个操作，而且是乱序的

整个设计有两个主要部分：

- 指令控制单元（Instruction Control Unit，ICU）
  - 负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作
- 执行单元（Execution Unit，EU）
  - 执行上面的操作

ICU从指令高速缓存（instruction cache）中读取指令，指令高速缓存是一个特殊的高速存储器，它包含最近访问的指令。

- ICU会在当前正在执行的指令很早之前取指，这样它才有足够的时间对指令译码，并把操作发送到EU。
- 如果当程序遇到分支时，程序有两个可能的前进方向
  - 一种可能会选择分支，控制被传递到分支目标
  - 另一种，不选择分支，控制被传递到指令序列的下一条指令

**现代处理器采用了一种分支预测的技术，处理器会猜测是否会选择分支，同时还预测分支的目标地址**

使用投机执行（speculative execution）的技术，处理器会开始取出位于它预测的分支会跳到的地方的指令，并对指令译码，甚至在它确定分支预测是否正确之前就开始执行这些操作。

如果过后确定分支预测错误，会将状态重新设置到分支点的状态，并开始取出和执行另一个方向上的指令。标记为取指控制的块，包括分支预测，以完成确定取哪些指令的任务。

**任何对程序寄存器的更新都只会在指令退役时才会发生，只有在处理器能够确信导致这条指令的所有分支都预测正确了，才会这样做**

#### 5.8 循环展开

通过增加每次迭代计算的元素的数量，减少循环的迭代次数

```c
void combine5(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *data = get_vec_start(v);
  data_t acc = IDENT;
  // combine 2 elements at a time
  for(i = 0; i < limit; i+=2){
    acc = (acc OP data[i]) OP data[i+1];
  }
  
  // finish any remaning elements
  for(; i < length; i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

#### 5.9 提高并行性

**程序的性能是受运算单元的延迟限制的**

##### 5.9.1 多个累积变量

将一组合并运算分割成两个或更多的部分，并在最后合并结果来提高性能

感觉这样有点夸张了。。。但是性能确实提高了

```c
void combine6(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *data = get_vec_start(v);
  data_t acc0 = IDENT;
  
  // combine 2 elements at a time
  for(i = 0; i < limit; i+=2){
    acc0 = acc0 OP data[i];
    acc1 = acc1 OP data[i+1];
  }
  
  // finish any remaning elements
  for(; i < length; i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

##### 5.9.2 重新结合变换

另一种打破顺序相关从而使得性能提高到延迟界限之外的方法

```c
void combine6(vec_ptr v, data_t *dest){
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *data = get_vec_start(v);
  data_t acc0 = IDENT;
  
  // combine 2 elements at a time
  for(i = 0; i < limit; i+=2){
    acc = acc OP (data[i] OP data[i+1]);
  }
  
  // finish any remaning elements
  for(; i < length; i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

#### 5.11 一些限制因素

关键路径指明了执行该程序所需时间的一个基本的下界

##### 5.11.1 寄存器溢出

循环并行性的好处受汇编代码描述计算的能力限制。

如果我们的并行度p超过了可用的寄存器数量，那么编译器会诉诸溢出（spilling），将某些临时值存放到内存中，通常是在运行时堆栈上分配空间。

##### 5.11.2 分支预测和预测错误处罚

通用规则

- 不要过分关心可预测的分支
- 书写适合用条件传送实现的代码

```c
void minmax1(long a[], long b[], long n){
  long i;
  for(i = 0; i < n; i++){
    if(a[i] > b[i]){
      long t = a[i];
      a[i] = b[i];
      b[i] = t;
    }
  }
}
```

使用条件传送后

```c
void minmax1(long a[], long b[], long n){
  long i;
  for(i = 0; i < n; i++){
    long min = a[i] < b[i] ? a[i] : b[i];
    long max = a[i] < b[i] ? b[i] : a[i];
    a[i] = min;
    b[i] = max;
  }
}
```

#### 5.12 理解内存性能

##### 5.12.1 加载的性能

加载操作的地址只依赖于循环索引``i``，所以加载操作不会成为限制性能的关键路径的一部分

##### 5.12.2 存储的性能

存储操作并不影响任何寄存器值，因此，一系列存储操作不会产生数据相关。

- 只有加载操作会受存储操作结果的影响，因为只有加载操作能从由存储操作写的那个位置读回值

**存储单元包含一个存储缓冲区**，它包含已经被发射到存储单元而又还没有完成的存储操作的地址和数据，这里的完成包括更新数据高速缓存。

- 提供这样一个缓冲区，使得一系列存储操作不必等待每个操作都更新高速缓存就能够执行
- 当一个加载操作发生时，它必须检查存储缓冲区中的条目，看有没有地址相匹配

#### 5.13 应用：性能提高技术

优化程序性能的基本策略

- 高级设计。为遇到的问题选择适当的算法和数据结构
- 基本编码原则。避免限制优化的因素，这样编译器产生高效的代码
  - 消除连续的函数调用。**将计算移到循环外**
  - 消除不必要的内存引用。**引用临时变量来保存中间结果，只有在最后的值计算出来，才将结果存放到数组或全局变量中**
  - 假设没有执行内联替换，则调用消息相当可靠
  - 默认情况下，不会显示对库函数的计时。相反，库函数的时间都被计算到调用它们的函数的时间中

### 第六章 存储器层次结构

存储器系统是一个线性的字节数组，而CPU能够在一个常数时间内访问每个存储器的位置

#### 6.1 存储技术

##### 6.1.1 随机访问存储器

**静态RAM（SRAM）要比动态RAM（DRAM）更快**

- SRAM用来作为高速缓存存储器，既可以在CPU芯片上，也可以在片下
- DRAM用来作为主存以及图形系统的帧缓冲区

**1.静态RAM**

- SRAM将每个位存储在一个双稳态的（bistable）存储器单元里
- 每个单元是用一个六晶体管电路来实现的
- 只要有电，它就会永远地保持它的值

**2.动态RAM**

- DRAM将每个位存储为对一个电容的充电

**4.内存模块**

- DRAM芯片封装在内存模块（memory module）中，它插到主板的扩展槽上
- Core i7，系统使用的240个引脚的双列直插内存模块，它以64位为块传送数据到内存控制器和从内存控制器传出数据

**6.非易失性存储器**

**如果断电，DRAM和SRAM会丢失它们的信息**

非易失性存储器，一般都是只读存储器

**7.访问主存**

数据流通过称为总线（bus）的共享电子电路在处理器和DRAM主存之间来来回回

每次CPU和主存之间的数据传送都是通过一系列步骤来完成的，**这些步骤称为总线事务**

- 读事务从主存传送数据到CPU
- 写事务从CPU传送数据到主存

**总线是一组并行的导线，能携带地址、数据和控制信号**

##### 6.1.2 磁盘存储

**1.磁盘构造**

磁盘是由盘片构成的

- 每个盘片有两面或者称为表面，表面覆盖着磁性记录材料
- 盘片中央有一个可以旋转的主轴，它使得盘片以固定的旋转速率旋转，**通常是5400-15000转每分钟（Revolution Per Minuete，RPM）**
- 磁盘通常包含一个或多个这样的盘片，并封装在一个密封的容器内

磁盘制造商通常用术语柱面来描述多个盘片驱动器的构造

- 柱面是所有盘片表面上到主轴中心的距离相等的磁道的集合

**2.磁盘容量**

一个磁盘上可以记录的最大位数称为它的最大容量，或者简称容量

磁盘容量是由以下技术因素决定的

- 记录密度：磁道一英寸的段中可以放入的位数
- 磁道密度：从盘片中心出发半径上一英寸的段内可以有的磁道数
- 面密度：记录密度与磁道密度的乘积

**3.磁盘操作**

磁盘用读/写头来读写存储在磁性表面的位，而读写头连接到一个传动臂一端

- 通过沿着半径轴前后移动这个传动臂，驱动器可以将读/写头定位在盘面上的任何磁道上。这样的机械运动称为寻道（seek）

**在任何时刻，所有的读/写都位于同一个柱面上**

**磁盘以扇区大小的块来读写数据，对扇区的访问时间有三个主要的部分：**

- 寻道时间
- 旋转时间
- 传送时间

**为什么实际磁盘容量比购买的容量要小？**

- 磁盘控制器必须对磁盘进行格式化，然后才能在该磁盘上存储数据
- 格式化包括用标识扇区的信息填写扇区之间的间隙，标识出表面有故障的柱面并且不使用它们，**以及在每个区中预留出一组柱面作为备用**，如果区中一个或多个柱面在磁盘使用过程中坏掉了，就可以使用这些备用的柱面
- **因为存在这些备用的柱面，所以磁盘制造商所说的格式化容量比最大容量要小**

**6.访问磁盘**

CPU使用一种称为内存映射I/O的技术来向I/O设备发射命令

在使用内存映射I/O的系统中，地址空间中有一块地址是为与I/O设备通信保留的

- 每个这样的地址称为一个I/O端口（I/O port）

在磁盘控制器收到来自CPU的读命令后，它将逻辑块号翻译成一个扇区地址，读该扇区的内容，然后将这些内容直接传送到主存，不需要CPU的干涉

设备可以自己执行读或者写总线事务而不需要CPU干涉读过程，称为直接内存访问（Direct Memory Access，DMA）

- 这种数据传送称为DMA传送

- 在DMA传送完成，磁盘扇区内容被安全地存储在主存中以后，磁盘控制器通过给CPU发送一个中断信号来通知CPU。
- **基本思想是中断会发信号到CPU芯片的一个外部引脚上，这会导致CPU暂停它当前正在做的工作，跳转到一个操作系统例程**，这个程序会记录I/O已经完成，然后将控制返回到CPU被中断的地方

##### 6.1.3 固态硬盘

固态硬盘（Solid State Disk，SSD）是一种基于闪存的存储技术

SSD封装插到I/O总线上标准硬盘插槽中，行为就和其他硬盘一样，处理来自CPU的读写逻辑磁盘块的请求

一个SSD封装由一个或多个闪存芯片和闪存翻译层组成，闪存芯片替代传统旋转磁盘中的机械驱动器，而闪存翻译层是一个硬件/固件设备，扮演与磁盘控制器相同的角色，将对逻辑块的请求翻译成对底层物理设备的访问

#### 6.2 局部性

局部性有两种不同的形式：时间局部性和空间局部性

##### 6.2.1 对程序数据引用的局部性

好的局部性程序

```c
int sumarrayrows(int a[M][N]){
  int i, j, sum = 0;
  for(i = 0; i < M; i++){
    for(j = 0; j < N; j++){
      sum += a[i][j];
    }
  }
  return sum;
}
```

坏的局部性

```c
int sumarraycols(int a[M][N]){
  int i, j, sum = 0;
  for(j = 0; j < M; j++){
    for(i = 0; i < N; i++){
      sum += a[i][j];
    }
  }
  return sum;
}
```

##### 6.2.2 局部性小结

评价局部性的一些简单原则

- 重复引用相同变量的程序有良好的时间局部性
- 对于具有步长为k的引用模式的程序，步长越小，空间局部性越好
- 对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好

#### 6.4 高速缓存存储器

##### 6.4.2 直接映射高速缓存

高速缓存确定一个请求是否命中，然后抽取出被请求的字的过程

- 组选择
- 行匹配
- 字抽取

**高速缓存行、组和块有什么区别？**

- 块是一个固定大小的信息包，在高速缓存和主存（或下一层高速缓存）之间来回传送
- 行是高速缓存中的一个容器，存储块以及其他信息（例如有效位和标记位）
- 组是一个或多个行的集合。直接映射高速缓存中的组只由一行组成。组相联和全相联高速缓存中的组是由多个行组成的

**在直接映射高速缓存中，组和行实际上是等价的，在相联高速缓存中，组和行是很不一样的，这两个词不能互换使用**

#### 6.5 编写高速缓存友好的代码

基本方法

- 让最常见的情况运行得快
- 尽量减小每个循环内部的缓存不命中数量

### 第七章 链接

链接是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行

链接可以执行于编译时，也就是在源代码被翻译成机器代码时；也可以执行于运行时，也就是由应用程序来执行

 #### 7.1 编译器驱动程序

main.c

```c
int sum(int *a, int n);
int array[2] = {1, 2};
int main(){
  int val = sum(array, 2);
  return val;
}
```

sum.c

```c
int sum(int *a, int n){
  int i, s = 0;
  for(i = 0; i < n; i++){
    s += a[i];
  }
  return s;
}
```

调用GCC驱动程序``gcc -Og -o prog main.c sum.c``

- 生成-o文件之后，再运行链接程序ld，将main.o和sum.o以及一些必要的系统目标文件组合起来，创建一个可执行目标文件

#### 7.4 可重定位目标文件

不同节的位置和大小是由节头部表描述的，其中目标文件中每个节都有一个固定大小的条目（entry）

典型的ELF可重定位目标文件包含下面几个节

- .text：已编译程序的机器代码
- .rodata：只读数
- .data：已初始化的全局和静态C变量
- .bss：未初始化的全局和静态C变量
- .symtab：一个符号表，它存放在程序中定义和引用的函数和全局变量的信息
- .rel.text：一个.text节中位置的列表，当链接器把这个目标文件和其他文件组合时，需要修改这些位置
- .rel.data：被模块引用或定义的所有全局变量的重定位信息
- .debug：一个调试符号表，其条目是程序中定义的局部变量和类型定义，程序中定义和引用的全局变量，以及原始的C源文件
- .line：原始C源程序中的行号和.text节中机器指令之间的映射
- .strtab：一个字符串表，其内容包括.symtab和.debug节中的符号表，以及节头部中的节名字

**为什么未初始化的数据称为.bss**

- 起始于IBM704汇编语言中“块存储开始（Block Storage Start）”指令的首字母缩写
- .data和.bss节之间区别的简单方法是把"bss"看成是“更好地节省空间（Better Save Space）的缩写

**定义为带有static属性的本地过程变量是不在栈中管理的。相反，编译器在.data或.bss中为每个定义分配空间，并在符号表中创建一个有唯一名字的本地链接器符号**

COMMON和.bss的区别

- COMMON：未初始化的全局变量
- .bss：未初始化的静态变量，以及初始化为0的全局或静态变量

#### 7.6 符号解析

链接器解析符号引用的方法是将每个引用与它输入的可重定位目标文件的符号表中的一个确定的符号定义关联起来。

##### 7.6.1 链接器如何解析多重定义的全局符号

Linux链接器使用下面的规则来处理多重定义的符号名

- 规则1：不允许有多个同名的强符号
- 规则2：如果有一个强符号和多个弱符号同名，那么选择强符号
- 规则3：如果有多个弱符号同名，那么从这些弱符号中任意选择一个

``gcc foo.c bar.c``

两个main，会报错，main是强符号

```c
// foo.c
int main(){}
// bar.c
int main(){}
```

强符号x被定义了两次

```c
// foo.c
int x = 123;
// bar.c
int x = 123;
```

一强一弱，不报错

```c
// foo.c
int x = 123;
// bar.c
int x;
```

两个弱，不报错，但是这种会引起歧义，如果后续修改了这个值就很难控制了

```c
// foo.c
int x;
// bar.c
int x;
```

类型不同也是，链接的时候只会warning，并不是error

```c
// foo.c
int x;
// bar.c
double x;
```

##### 7.6.2 与静态库链接

在链接时，链接器只复制被程序引用的目标模块，这就减少了可执行文件在磁盘和内存中的大小

在Linux中，静态库以一种称为存档（archive）的特殊文件格式存放在磁盘中

- 存档文件是一组连接起来的可重定位目标文件的集合，有一个头部用来描述每个成员目标文件的大小和位置
- 存档文件名由后缀.a标识

#### 7.8 可执行目标文件

可执行目标文件的格式类似于可重定位目标文件的格式

ELF头描述文件的总体格式，它还包括程序的入口点，也就是当程序运行时要执行的第一条指令的地址。

**.text、.rodata和.data节与可重定位目标文件中的节是相似的，除了这些节已经被重定位到它们最终到运行时内存地址以外，.init节定义了一个小函数，叫做_init，程序的初始化代码会调用它**

ELF可执行文件被设计得很容易加载到内存，可执行文件的连续的片（chunk）被映射到连续的内存段

#### 7.9 加载可执行文件

在Linux shell命令行中输入运行的名字

```bash
linux> ./prog
```

因为prog不是一个内置的shell命令，所以shell会认为prog是一个可执行目标文件，通过调用某个驻留在存储器中称为加载器（loader）的操作系统代码来运行它

**加载器将可执行目标文件中的代码和数据从磁盘复制到内存中，然后通过跳转到程序的第一条指令或入口点来运行该程序。**

- 这个将程序复制到内存并运行的过程叫做加载

**加载器实际是如何工作的？**

- Linux系统中的每个程序都运行在一个进程上下文中，有自己的虚拟地址空间。
- 当shell运行一个程序时，父shell进程生成一个子进程，它是父进程的一个复制。
- 子进程通过execve系统调用启动加载器。
- 加载器删除子进程现有的虚拟内存段，并创建一组新的代码、数据、堆和栈段。
- 新的栈和堆段被初始化为零。
- 通过将虚拟地址空间中的页映射到可执行文件的页大小的片（chunk），新的代码和数据段被初始化为可执行文件的内容。
- 最后，加载器跳转到_start地址，它最终会调用应用程序的main函数。
- 除了一些头部信息，在加载过程中没有任何从磁盘到内存的数据复制。
- 直到CPU引用一个被映射的虚拟页时才会进行复制，此时，操作系统利用它的页面调度机制自动将页面从磁盘传送到内存

#### 7.10 动态链接共享库

**静态库缺点：静态库和所有的软件一样，需要定期维护和更新。**

共享库（shared library）是致力于解决静态库缺陷的一个现代创新产物。

共享库是一个目标模块，在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。

- **这个过程称为动态链接，是由一个叫做动态链接器的程序来执行的**
- 微软的操作系统大量地使用了共享库，它们称为DLL（动态链接库）

对于一个库只有一个.so文件。所有引用该库的可执行目标文件共享这个.so文件中的代码和数据，而不是像静态库的内容那样被复制和嵌入到引用它们的可执行的文件中

**在内存中，一个共享库的.text节的一个副本可以被不同的正在运行的进程共享**

#### 7.11 从应用程序中加载和链接共享库

将每个生成动态内容的函数打包在共享库中

- 当一个来自Web浏览器的请求到达时，服务器动态地加载和链接适当的函数，然后直接调用它，而不是使用fork和execve在子进程的上下文中运行函数
- 函数会一直缓存在服务器的地址空间中，所以只要一个简单的函数调用的开销就可以处理随后的请求了
- **在运行时无需停止服务器，就可以更新已存在的函数，以及添加新的函数**

Linux系统为动态链接器提供了一个简单的接口，运行应用程序在运行时加载和链接共享库

```c
#include <dlfcn.h>
void *dlopen(const char *filename, int flag);
返回：若成功则为指向句柄的指针，若出错则为NULL
```

```c
#include <dlfcn.h>
void *dlsym(void *handle, char *symbol);
返回：若成功则为指向句柄的指针，若出错则为NULL
```

dlsym函数的输入是一个指向前面已经打开了的共享库的句柄和一个symbol名字

如果没有其他共享库还在使用这个共享库，dlcloes函数就卸载该共享库

```c
#include <dlfcn.h>
int dlclose(void *handle);
返回：成功为0，出错为-1
```

```c
#include <dlfcn.h>
const char *dlerror(void);
返回：如果前面堆dlopen、dlsym或dlclose的调用失败，则为错误消息，如果前面的调用成功，则为NULL
```

#### 7.12 位置无关代码

共享库的一个主要目的就是允许多个正在运行的进程共享内存中相同的库代码，因而节约宝贵的内存资源

现代系统以这样一种方式编译共享模块的代码段，使得可以把它们加载到内存的任何位置而无需链接器修改。

- 使用这种方法，无限多个进程可以共享一个共享模块的代码段段单一副本。（每个进程仍然会有它自己的读/写数据块）

**可以加载而无需重定位的代码称为位置无关代码（Position-Independent Code，PIC）。用户对GCC使用-fpic选项指示GNU编译系统生成PIC代码。共享库的编译必须总是使用该选项**

#### 7.13 库打桩机制

库打桩：允许我们截获对共享库函数的调用，取而代之执行自己的代码

使用打桩机制，可以追逐对某个特殊库函数的调用次数，验证和追逐它的输入和输出值，或者甚至把它替换成一个完全不同的实现

基本思想

- 给定一个需要打桩的目标函数，创建一个包装函数，它的原型与目标函数完全一样
- 使用某种特殊的打桩机制，你就可以欺骗系统调用包装函数而不是目标函数了
- 包装函数通常会执行它自己的逻辑，然后调用目标函数，再将目标函数的返回值传递给调用者

### 第八章 异常控制流

现代系统通过使控制流发生突变来对这些情况做出反应。

- 称为异常控制流（Exceptional Control Flow，ECF）

理解ECF很重要，有很多原因

- 理解ECF将帮助你理解重要的系统概念
- 理解ECF将帮助你理解应用程序是如何与操作系统交互的
- 理解ECF将帮助你编写有趣的新应用程序
- 理解ECF将帮助你理解并发
- 理解ECF将帮助你理解软件异常如何工作

#### 8.1 异常

**异常时异常控制流的一种形式，它一部分由硬件实现，一部分由操作系统实现**

异常的剖析

- 处理器状态中的变化（事件）触发从应用程序到异常处理程序到突发的控制转移（异常）
- 在异常处理程序完成处理后，它将控制返回给被中断的程序或者终止

**在任何情况下，当处理器检测到有事件发生时，它就会通过一张叫做异常表（exception table）的跳转表（系统启动时分配初始化的），进行一个间接过程调用（异常），到一个专门设计用来处理这类事件的操作系统子程序（异常处理程序（exception handler））**

##### 8.1.1 异常处理

系统中可能的每种类型的异常都分配了一个唯一的非负整数的异常号

- 其中一些号码是由处理器的设计者分配的，其他号码是由操作系统内核的设计者分配的
- 前者的示例包括被零除、缺页、内存访问违例、断点以及算术运算溢出
- 后者的示例包括系统调用和来自外部I/O设备的信号

**异常表的起始地址放在一个叫做异常表基址寄存器的特殊CPU寄存器**

异常类似于过程调用，也有一些重要的不同之处

- 过程调用时，在跳转到处理程序之前，处理器将返回地址压入栈中。然而，根据异常的类型，返回地址要么是当前指令（当事件发生时正在执行的指令），要么是下一条指令（如果事件不发生，将会在当前指令后执行的指令）
- 处理器也把一些额外的处理器状态压到栈里，在处理程序返回时，重新开始执行被中断的程序会需要这些状态
- 如果控制从用户程序转移到内核，所有这些项目都被压到内核栈中，而不是压到用户栈中
- 异常处理程序运行在内核模式下，这意味着它们对所有的系统资源都有完全的访问权限

**一旦硬件触发了异常，剩下的工作就是由异常处理程序在软件中完成**

##### 8.1.2 异常的类别

**1.中断**

- 中断是异步发生的，是来自处理器外部的I/O设备的信号的结果

**2.陷阱和系统调用**

- 陷阱是有意的异常，是执行一条指令的结果
- **陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用**
- 普通函数在用户态，系统调用在内核态

**3.故障**

- 故障由错误情况引起，它可能能够被故障处理程序修正
- 经典的故障示例是缺页异常，当指令引用一个虚拟地址，而与该地址相对应的物理页面不在内存中，因此必须从磁盘中取出时，就会发生故障

**4.终止**

- 终止是不可恢复的致命错误造成的结果，通常是一些硬件错误，比如DRAM或者SRAM位被损坏时发生的奇偶错误
- 终止处理程序从不将控制返回给应用程序

##### 8.1.3 Linux/x86-64系统中的异常

**1.Linux/x86-64故障和终止**

- 除法错误。当除零时，或者当一个除法指令的结果对于目标操作数来说太大了时候，就会发生除法错误。**错误报告：浮点异常（Floating exception）**
- 一般保护故障。通常是因为一个程序引用了一个未定义的虚拟内存区域，或者因为程序试图写一个只读的文本段。**错误报告：段故障（Segmentation fault）**
- 缺页。处理程序将适当的磁盘上虚拟内存的一个页面映射到物理内存的一个页面，然后重新执行这条产生故障的指令。
- 机器检查。在导致故障的指令执行中检测到致命的硬件错误时发生的。

**2.Linux/x86-64系统调用**

- 每个系统调用都有一个唯一的整数号，对应于一个到内核中跳转表的偏移量（注意：这个跳转表和异常表不一样）
- 系统调用是通过一条称为syscall的陷阱指令来提供的
- 所有到Linux系统调用的参数都是通过通用寄存器而不是栈传递的

#### 8.2 进程

异常是允许操作系统内核提供进程（process）概念的基本构造块

进程的经典定义就是一个执行中程序的实例。系统中的每个程序都运行在某个进程的上下文（context）中。

- 上下文是由程序正确运行所需的状态组成的
- 这个状态包括存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合

##### 8.2.1 逻辑控制流

进程为每个程序提供了一种假象，好像程序在独占地使用处理器。

CPU会周期性地停顿，每次CPU停顿，它随后会继续执行我们的程序，并不改变程序内存位置或寄存器的内容

##### 8.2.2 并发流

多个流并发地执行的一般现象被称为并发（concurrency）

一个进程和其他进程轮流运行的概念称为多任务（multitasking）

一个进程执行它的控制流的一部分的每一时间段叫做时间片（time slice）

多任务也叫做时间分片（time slicing）

**注意，并发流的思想与流运行的处理器核数或者计算机无关**

如果两个流在时间上重叠，那么它们就是并发的，即使它们是运行在同一个处理器上

##### 8.2.4 用户模式和内核模式

一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中的任何内存位置

没有设置模式位时，进程就运行在用户模式中。

- 用户模式中的进程不允许执行特权指令（privileged instruction），比如停止处理器、改变模式位，或者发起一个I/O操作

**用户程序必须通过系统调用接口间接地访问内核代码和数据**

运行应用程序代码的进程初始化是在用户模式中的。进程从用户模式变为内核模式的唯一方法是通过诸如中断、故障或者陷入系统调用这样的异常。

- 当异常发生时，控制传递到异常处理程序，处理器将模式从用户模式变为内核模式
- 处理程序运行在内核模式中，当它返回到应用程序代码时，处理器就把模式从内核模式改回到用户模式

